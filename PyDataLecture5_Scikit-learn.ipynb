{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-learn for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preparation\n",
    "\n",
    "- Download and Install [Anaconda](https://www.continuum.io/downloads) (Python 3 version)\n",
    "- Run command in a new shell: `jupyter lab`\n",
    "- If you run jupyter lab in a linux server through ssh, open a new terminal\n",
    "    - `ssh -L 8000:localhost:(jupyter port, default is 8888) (user)@(server address)`\n",
    "    - after log in, `jupyter notebook list`, check and copy the token of your jupyter\n",
    "    - open browser http://localhost:8000/, enter the token\n",
    "- Create a new notebook: Left-upper area -> \"+\" (New launcher) -> Notebook -> Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Scikit-learn?\n",
    "\n",
    "- Scikit-learn: Machine Learning in Python\n",
    "    - Simple and efficient tools for data mining and data analysis\n",
    "    - Accessible to everybody, and reusable in various contexts\n",
    "    - Built on NumPy, SciPy, and matplotlib\n",
    "    - Open source, commercially usable - BSD license\n",
    "- Features:\n",
    "    - Classification\n",
    "    - Regression\n",
    "    - Clustering\n",
    "    - Dimensionality reduction\n",
    "    - Model selection\n",
    "    - Preprocessing\n",
    "\n",
    "Reference: [Scikit-learn official site](http://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. Machine Learning Theory\n",
    "    - Loss Function\n",
    "    - Training-Validation Sets\n",
    "    - Cross-Validation\n",
    "2. An Example for CV Training: Linear Regression\n",
    "3. Over-fitting\n",
    "    - Penalty Function\n",
    "    - Ridge and Lasso\n",
    "    - Select Penalty Coeffient\n",
    "4. Tree-based Models\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (1) Data Preprocessing\n",
    "Reference: [scikit-learn preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load modules and set options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3)\n",
    "pd.set_option('precision', 3)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53940, 10), (14232, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load price-missing data and true label data\n",
    "da = pd.read_csv(\"Diamonds.csv\", index_col = \"n\")\n",
    "da_true = pd.read_csv(\"Diamonds_predict_true.csv\", index_col = \"n\")\n",
    "da.shape, da_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53940,), (53940, 9))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate X and Y\n",
    "Y, X = da['price'], da.drop('price', axis = 1)\n",
    "Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14232,), (39708,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Denote labeled and unlabeled row index\n",
    "ir_unlab, ir_lab = da.index[Y.isna()], da.index[~Y.isna()]\n",
    "ir_unlab.shape, ir_lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to get help\n",
    "\n",
    "- From Function Help: ? + function\n",
    "    - `?metrics.log_loss`\n",
    "- From Autofill with *Tab*:\n",
    "    - `metrics.` + *Tab*\n",
    "- From Google: Your Question (what you want to do) + scikit-learn\n",
    "    - logistic regression scikit-learn\n",
    "    - speed up random forest scikit-learn\n",
    "- From Official Website: http://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn (1.1): Separate categorical and numerical variables\n",
    "\n",
    "- Categorical and numerical has different features\n",
    "- For categorical variables\n",
    "    - Create dummy variables\n",
    "- For numerical variables\n",
    "    - Scale with mean 0 and std 1\n",
    "    - Interaction / polynomial (if necessary)\n",
    "- For both\n",
    "    - Remove non-frequent variables\n",
    "    - Remove collinearity variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table     x     y     z\n",
       "n                                       \n",
       "1   0.23   61.5   55.0  3.95  3.98  2.43\n",
       "2   0.21   59.8   61.0  3.89  3.84  2.31\n",
       "3   0.23   56.9   65.0  4.05  4.07  2.31\n",
       "4   0.29   62.4   58.0  4.20  4.23  2.63\n",
       "5   0.31   63.3   58.0  4.34  4.35  2.75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric variable\n",
    "X_num = X.select_dtypes(np.number)\n",
    "X_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cut color clarity\n",
       "n                       \n",
       "1    Ideal     E     SI2\n",
       "2  Premium     E     SI1\n",
       "3     Good     E     VS1\n",
       "4  Premium     I     VS2\n",
       "5     Good     J     SI2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical variable\n",
    "X_cat = X.select_dtypes(\"object\")\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>color_H</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cut_Good  cut_Ideal  cut_Premium  cut_Very Good  color_E  color_F  color_G  \\\n",
       "n                                                                               \n",
       "1         0          1            0              0        1        0        0   \n",
       "2         0          0            1              0        1        0        0   \n",
       "3         1          0            0              0        1        0        0   \n",
       "4         0          0            1              0        0        0        0   \n",
       "5         1          0            0              0        0        0        0   \n",
       "\n",
       "   color_H  color_I  color_J  clarity_IF  clarity_SI1  clarity_SI2  \\\n",
       "n                                                                    \n",
       "1        0        0        0           0            0            1   \n",
       "2        0        0        0           0            1            0   \n",
       "3        0        0        0           0            0            0   \n",
       "4        0        1        0           0            0            0   \n",
       "5        0        0        1           0            0            1   \n",
       "\n",
       "   clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "n                                                        \n",
       "1            0            0             0             0  \n",
       "2            0            0             0             0  \n",
       "3            1            0             0             0  \n",
       "4            0            1             0             0  \n",
       "5            0            0             0             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable using a DataFrame way\n",
    "X_cat_dummy = pd.get_dummies(X_cat, drop_first=True)\n",
    "X_cat_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn (1.2): Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.536</td>\n",
       "      <td>-1.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-1.659</td>\n",
       "      <td>-1.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-3.385</td>\n",
       "      <td>3.376</td>\n",
       "      <td>-1.499</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>-1.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-1.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.029</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.212</td>\n",
       "      <td>-1.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>-0.207</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.138</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53940</th>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table      x      y      z\n",
       "n                                              \n",
       "1     -1.198 -0.174 -1.100 -1.588 -1.536 -1.571\n",
       "2     -1.240 -1.361  1.586 -1.641 -1.659 -1.741\n",
       "3     -1.198 -3.385  3.376 -1.499 -1.457 -1.741\n",
       "4     -1.072  0.454  0.243 -1.365 -1.317 -1.288\n",
       "5     -1.029  1.082  0.243 -1.240 -1.212 -1.118\n",
       "...      ...    ...    ...    ...    ...    ...\n",
       "53936 -0.164 -0.663 -0.205  0.017  0.022 -0.055\n",
       "53937 -0.164  0.943 -1.100 -0.037  0.014  0.101\n",
       "53938 -0.207  0.733  1.138 -0.063 -0.048  0.030\n",
       "53939  0.131 -0.523  0.243  0.373  0.338  0.285\n",
       "53940 -0.101  0.315 -1.100  0.088  0.119  0.143\n",
       "\n",
       "[53940 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale using a DataFrame way\n",
    "(X_num - X_num.mean()) / X_num.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.198, -0.174, -1.1  , -1.588, -1.536, -1.571],\n",
       "       [-1.24 , -1.361,  1.586, -1.641, -1.659, -1.741],\n",
       "       [-1.198, -3.385,  3.376, -1.499, -1.457, -1.741],\n",
       "       ..., \n",
       "       [-0.207,  0.733,  1.138, -0.063, -0.048,  0.03 ],\n",
       "       [ 0.131, -0.523,  0.243,  0.373,  0.338,  0.285],\n",
       "       [-0.101,  0.315, -1.1  ,  0.088,  0.119,  0.143]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale using a scikit-learn way\n",
    "model_scale = preprocessing.StandardScaler()\n",
    "X_num_arr = model_scale.fit_transform(X_num)\n",
    "X_num_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.798,  61.749,  57.457,   5.731,   5.735,   3.539])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scale.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.474,  1.433,  2.234,  1.122,  1.142,  0.706])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scale.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn (1.3): Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.198e+00,  -1.741e-01,  -1.100e+00, ...,   2.439e+00,\n",
       "          2.495e+00,   2.414e+00],\n",
       "       [ -1.240e+00,  -1.361e+00,   1.586e+00, ...,   2.723e+00,\n",
       "          2.858e+00,   2.888e+00],\n",
       "       [ -1.198e+00,  -3.385e+00,   3.376e+00, ...,   2.184e+00,\n",
       "          2.609e+00,   2.538e+00],\n",
       "       ..., \n",
       "       [ -2.066e-01,   7.333e-01,   1.138e+00, ...,   3.028e-03,\n",
       "         -1.912e-03,  -1.439e-03],\n",
       "       [  1.309e-01,  -5.231e-01,   2.429e-01, ...,   1.260e-01,\n",
       "          1.065e-01,   9.626e-02],\n",
       "       [ -1.011e-01,   3.145e-01,  -1.100e+00, ...,   1.045e-02,\n",
       "          1.264e-02,   1.702e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly = preprocessing.PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_num_poly_arr = model_poly.fit_transform(X_num_arr)\n",
    "X_num_poly_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0',\n",
       " 'x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'x5',\n",
       " 'x0 x1',\n",
       " 'x0 x2',\n",
       " 'x0 x3',\n",
       " 'x0 x4',\n",
       " 'x0 x5',\n",
       " 'x1 x2',\n",
       " 'x1 x3',\n",
       " 'x1 x4',\n",
       " 'x1 x5',\n",
       " 'x2 x3',\n",
       " 'x2 x4',\n",
       " 'x2 x5',\n",
       " 'x3 x4',\n",
       " 'x3 x5',\n",
       " 'x4 x5']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': 'carat', 'x1': 'depth', 'x2': 'table', 'x3': 'x', 'x4': 'y', 'x5': 'z'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_dict = {\"x{}\".format(i): i_val for i, i_val in enumerate(X_num.columns)}\n",
    "poly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.536</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>0.209</td>\n",
       "      <td>1.318</td>\n",
       "      <td>1.902</td>\n",
       "      <td>1.841</td>\n",
       "      <td>1.882</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1.728</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-1.659</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>1.688</td>\n",
       "      <td>-1.967</td>\n",
       "      <td>2.036</td>\n",
       "      <td>2.057</td>\n",
       "      <td>2.160</td>\n",
       "      <td>-2.157</td>\n",
       "      <td>2.233</td>\n",
       "      <td>2.257</td>\n",
       "      <td>2.369</td>\n",
       "      <td>-2.602</td>\n",
       "      <td>-2.630</td>\n",
       "      <td>-2.761</td>\n",
       "      <td>2.723</td>\n",
       "      <td>2.858</td>\n",
       "      <td>2.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-3.385</td>\n",
       "      <td>3.376</td>\n",
       "      <td>-1.499</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>4.056</td>\n",
       "      <td>-4.045</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.746</td>\n",
       "      <td>2.086</td>\n",
       "      <td>-11.427</td>\n",
       "      <td>5.073</td>\n",
       "      <td>4.933</td>\n",
       "      <td>5.894</td>\n",
       "      <td>-5.059</td>\n",
       "      <td>-4.920</td>\n",
       "      <td>-5.878</td>\n",
       "      <td>2.184</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.412</td>\n",
       "      <td>1.380</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.798</td>\n",
       "      <td>1.758</td>\n",
       "      <td>1.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.029</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.212</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.277</td>\n",
       "      <td>1.248</td>\n",
       "      <td>1.151</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>-1.210</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.503</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9   \\\n",
       "n                                                                         \n",
       "1 -1.198 -0.174 -1.100 -1.588 -1.536 -1.571  0.209  1.318  1.902  1.841   \n",
       "2 -1.240 -1.361  1.586 -1.641 -1.659 -1.741  1.688 -1.967  2.036  2.057   \n",
       "3 -1.198 -3.385  3.376 -1.499 -1.457 -1.741  4.056 -4.045  1.796  1.746   \n",
       "4 -1.072  0.454  0.243 -1.365 -1.317 -1.288 -0.487 -0.260  1.463  1.412   \n",
       "5 -1.029  1.082  0.243 -1.240 -1.212 -1.118 -1.114 -0.250  1.277  1.248   \n",
       "\n",
       "      10      11     12     13     14     15     16     17     18     19  \\\n",
       "n                                                                          \n",
       "1  1.882   0.191  0.276  0.267  0.274  1.746  1.689  1.728  2.439  2.495   \n",
       "2  2.160  -2.157  2.233  2.257  2.369 -2.602 -2.630 -2.761  2.723  2.858   \n",
       "3  2.086 -11.427  5.073  4.933  5.894 -5.059 -4.920 -5.878  2.184  2.609   \n",
       "4  1.380   0.110 -0.620 -0.598 -0.585 -0.332 -0.320 -0.313  1.798  1.758   \n",
       "5  1.151   0.263 -1.342 -1.312 -1.210 -0.301 -0.294 -0.272  1.503  1.386   \n",
       "\n",
       "      20  \n",
       "n         \n",
       "1  2.414  \n",
       "2  2.888  \n",
       "3  2.538  \n",
       "4  1.696  \n",
       "5  1.355  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_poly = pd.DataFrame(X_num_poly_arr, X_num.index)\n",
    "X_num_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>carat depth</th>\n",
       "      <th>carat table</th>\n",
       "      <th>carat x</th>\n",
       "      <th>carat y</th>\n",
       "      <th>carat z</th>\n",
       "      <th>depth table</th>\n",
       "      <th>depth x</th>\n",
       "      <th>depth y</th>\n",
       "      <th>depth z</th>\n",
       "      <th>table x</th>\n",
       "      <th>table y</th>\n",
       "      <th>table z</th>\n",
       "      <th>x y</th>\n",
       "      <th>x z</th>\n",
       "      <th>y z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.536</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>0.209</td>\n",
       "      <td>1.318</td>\n",
       "      <td>1.902</td>\n",
       "      <td>1.841</td>\n",
       "      <td>1.882</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1.728</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-1.659</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>1.688</td>\n",
       "      <td>-1.967</td>\n",
       "      <td>2.036</td>\n",
       "      <td>2.057</td>\n",
       "      <td>2.160</td>\n",
       "      <td>-2.157</td>\n",
       "      <td>2.233</td>\n",
       "      <td>2.257</td>\n",
       "      <td>2.369</td>\n",
       "      <td>-2.602</td>\n",
       "      <td>-2.630</td>\n",
       "      <td>-2.761</td>\n",
       "      <td>2.723</td>\n",
       "      <td>2.858</td>\n",
       "      <td>2.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-3.385</td>\n",
       "      <td>3.376</td>\n",
       "      <td>-1.499</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>4.056</td>\n",
       "      <td>-4.045</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.746</td>\n",
       "      <td>2.086</td>\n",
       "      <td>-11.427</td>\n",
       "      <td>5.073</td>\n",
       "      <td>4.933</td>\n",
       "      <td>5.894</td>\n",
       "      <td>-5.059</td>\n",
       "      <td>-4.920</td>\n",
       "      <td>-5.878</td>\n",
       "      <td>2.184</td>\n",
       "      <td>2.609</td>\n",
       "      <td>2.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.412</td>\n",
       "      <td>1.380</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.798</td>\n",
       "      <td>1.758</td>\n",
       "      <td>1.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.029</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.212</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>-1.114</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.277</td>\n",
       "      <td>1.248</td>\n",
       "      <td>1.151</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>-1.210</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.503</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table      x      y      z  carat depth  carat table  \\\n",
       "n                                                                       \n",
       "1 -1.198 -0.174 -1.100 -1.588 -1.536 -1.571        0.209        1.318   \n",
       "2 -1.240 -1.361  1.586 -1.641 -1.659 -1.741        1.688       -1.967   \n",
       "3 -1.198 -3.385  3.376 -1.499 -1.457 -1.741        4.056       -4.045   \n",
       "4 -1.072  0.454  0.243 -1.365 -1.317 -1.288       -0.487       -0.260   \n",
       "5 -1.029  1.082  0.243 -1.240 -1.212 -1.118       -1.114       -0.250   \n",
       "\n",
       "   carat x  carat y  carat z  depth table  depth x  depth y  depth z  table x  \\\n",
       "n                                                                               \n",
       "1    1.902    1.841    1.882        0.191    0.276    0.267    0.274    1.746   \n",
       "2    2.036    2.057    2.160       -2.157    2.233    2.257    2.369   -2.602   \n",
       "3    1.796    1.746    2.086      -11.427    5.073    4.933    5.894   -5.059   \n",
       "4    1.463    1.412    1.380        0.110   -0.620   -0.598   -0.585   -0.332   \n",
       "5    1.277    1.248    1.151        0.263   -1.342   -1.312   -1.210   -0.301   \n",
       "\n",
       "   table y  table z    x y    x z    y z  \n",
       "n                                         \n",
       "1    1.689    1.728  2.439  2.495  2.414  \n",
       "2   -2.630   -2.761  2.723  2.858  2.888  \n",
       "3   -4.920   -5.878  2.184  2.609  2.538  \n",
       "4   -0.320   -0.313  1.798  1.758  1.696  \n",
       "5   -0.294   -0.272  1.503  1.386  1.355  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_poly.columns = pd.Series(model_poly.get_feature_names()).str.replace('x[0-9]+', lambda x: poly_dict.get(x.group()))\n",
    "X_num_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>carat depth</th>\n",
       "      <th>carat table</th>\n",
       "      <th>carat x</th>\n",
       "      <th>carat y</th>\n",
       "      <th>carat z</th>\n",
       "      <th>depth table</th>\n",
       "      <th>depth x</th>\n",
       "      <th>depth y</th>\n",
       "      <th>depth z</th>\n",
       "      <th>table x</th>\n",
       "      <th>table y</th>\n",
       "      <th>table z</th>\n",
       "      <th>x y</th>\n",
       "      <th>x z</th>\n",
       "      <th>y z</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>color_H</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>-1.536</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.553</td>\n",
       "      <td>1.542</td>\n",
       "      <td>1.596</td>\n",
       "      <td>1.207</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.852</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>1.226</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>2.123</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>2.206</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.361</td>\n",
       "      <td>1.586</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-1.659</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>1.526</td>\n",
       "      <td>-2.131</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-1.267</td>\n",
       "      <td>2.233</td>\n",
       "      <td>2.166</td>\n",
       "      <td>2.206</td>\n",
       "      <td>-2.801</td>\n",
       "      <td>-2.881</td>\n",
       "      <td>-2.947</td>\n",
       "      <td>1.441</td>\n",
       "      <td>1.629</td>\n",
       "      <td>1.129</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>1.706</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>2.123</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.769</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198</td>\n",
       "      <td>-3.385</td>\n",
       "      <td>3.376</td>\n",
       "      <td>-1.499</td>\n",
       "      <td>-1.457</td>\n",
       "      <td>-1.741</td>\n",
       "      <td>3.703</td>\n",
       "      <td>-4.192</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.817</td>\n",
       "      <td>-7.577</td>\n",
       "      <td>5.040</td>\n",
       "      <td>4.702</td>\n",
       "      <td>5.626</td>\n",
       "      <td>-5.261</td>\n",
       "      <td>-5.225</td>\n",
       "      <td>-6.101</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.415</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.161</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>2.123</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>2.367</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>1.706</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>2.991</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>1.844</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.029</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-1.240</td>\n",
       "      <td>-1.212</td>\n",
       "      <td>-1.118</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-1.302</td>\n",
       "      <td>-1.215</td>\n",
       "      <td>-1.266</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.235</td>\n",
       "      <td>3.161</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>4.267</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>2.206</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table      x      y      z  carat depth  carat table  \\\n",
       "n                                                                       \n",
       "1 -1.198 -0.174 -1.100 -1.588 -1.536 -1.571        0.166        1.127   \n",
       "2 -1.240 -1.361  1.586 -1.641 -1.659 -1.741        1.526       -2.131   \n",
       "3 -1.198 -3.385  3.376 -1.499 -1.457 -1.741        3.703       -4.192   \n",
       "4 -1.072  0.454  0.243 -1.365 -1.317 -1.288       -0.473       -0.438   \n",
       "5 -1.029  1.082  0.243 -1.240 -1.212 -1.118       -1.050       -0.428   \n",
       "\n",
       "   carat x  carat y  carat z  depth table  depth x  depth y  depth z  table x  \\\n",
       "n                                                                               \n",
       "1    0.667    0.617    0.670        0.332    0.298    0.281    0.173    1.553   \n",
       "2    0.763    0.767    0.870       -1.267    2.233    2.166    2.206   -2.801   \n",
       "3    0.590    0.551    0.817       -7.577    5.040    4.702    5.626   -5.261   \n",
       "4    0.351    0.319    0.308        0.276   -0.588   -0.539   -0.659   -0.528   \n",
       "5    0.217    0.205    0.142        0.380   -1.302   -1.215   -1.266   -0.497   \n",
       "\n",
       "   table y  table z    x y    x z    y z  cut_Good  cut_Ideal  cut_Premium  \\\n",
       "n                                                                            \n",
       "1    1.542    1.596  1.207  1.316  0.852    -0.316      1.226       -0.586   \n",
       "2   -2.881   -2.947  1.441  1.629  1.129    -0.316     -0.816        1.706   \n",
       "3   -5.225   -6.101  0.997  1.415  0.925     3.161     -0.816       -0.586   \n",
       "4   -0.516   -0.469  0.679  0.679  0.434    -0.316     -0.816        1.706   \n",
       "5   -0.490   -0.428  0.436  0.359  0.235     3.161     -0.816       -0.586   \n",
       "\n",
       "   cut_Very Good  color_E  color_F  color_G  color_H  color_I  color_J  \\\n",
       "n                                                                        \n",
       "1         -0.537    2.123   -0.464   -0.515   -0.427   -0.334   -0.234   \n",
       "2         -0.537    2.123   -0.464   -0.515   -0.427   -0.334   -0.234   \n",
       "3         -0.537    2.123   -0.464   -0.515   -0.427   -0.334   -0.234   \n",
       "4         -0.537   -0.471   -0.464   -0.515   -0.427    2.991   -0.234   \n",
       "5         -0.537   -0.471   -0.464   -0.515   -0.427   -0.334    4.267   \n",
       "\n",
       "   clarity_IF  clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  \\\n",
       "n                                                                   \n",
       "1      -0.185       -0.565        2.206       -0.423       -0.542   \n",
       "2      -0.185        1.769       -0.453       -0.423       -0.542   \n",
       "3      -0.185       -0.565       -0.453        2.367       -0.542   \n",
       "4      -0.185       -0.565       -0.453       -0.423        1.844   \n",
       "5      -0.185       -0.565        2.206       -0.423       -0.542   \n",
       "\n",
       "   clarity_VVS1  clarity_VVS2  \n",
       "n                              \n",
       "1         -0.27        -0.322  \n",
       "2         -0.27        -0.322  \n",
       "3         -0.27        -0.322  \n",
       "4         -0.27        -0.322  \n",
       "5         -0.27        -0.322  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_num_poly.join(X_cat_dummy)\n",
    "X = (X - X.mean()) / X.std()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn (1.4) Frequency and Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat           0.952\n",
       "depth           0.958\n",
       "table           0.817\n",
       "x               0.992\n",
       "y               0.992\n",
       "                ...  \n",
       "clarity_SI2     0.170\n",
       "clarity_VS1     0.151\n",
       "clarity_VS2     0.227\n",
       "clarity_VVS1    0.068\n",
       "clarity_VVS2    0.094\n",
       "Length: 38, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the values besides most frequent and NA to check frequency\n",
    "S_freq = X.apply(lambda x: pd.value_counts(x).iloc[1:].sum() / x.shape[0])\n",
    "S_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 38)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove sparse variables\n",
    "X = X.loc[:, S_freq > 0.01]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.028,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 0.182, -0.296,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       ..., \n",
       "       [-0.039, -0.009, -0.01 , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [-0.168, -0.023, -0.069, ..., -0.146,  0.   ,  0.   ],\n",
       "       [-0.137, -0.019, -0.062, ..., -0.175, -0.087,  0.   ]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a triangle correlation matrix to detect collinearity\n",
    "R = np.tril(np.corrcoef(X, rowvar=0), k=-1)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x', 'y', 'z', 'carat z', 'depth x', 'table x', 'table y', 'table z'], dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find last collinearity variables\n",
    "X.columns[(np.abs(R) > 0.95).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'x', 'y', 'carat depth', 'carat table', 'carat x', 'table x'], dtype='object')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find first collinearity variables\n",
    "X.columns[(np.abs(R) > 0.95).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 30)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove collinearity variables\n",
    "X = X.loc[:, ~(np.abs(R) > 0.95).any(axis=1)]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (2.1): Machine Learning Theory\n",
    "- Question of Machine Learning: given data $(X, Y)$, how to predict $Y$ with $X$?\n",
    "    - LM: $\\hat{Y} = X\\beta$\n",
    "    - GLM: $\\hat{Y} = g^{-1}(X\\beta)$\n",
    "    - Generally, $\\hat{Y} = f(X, \\theta)$, model family $f$ and parameter $\\theta$ can be complex\n",
    "- Compare *statistical modeling* with *machine learning*:\n",
    "    - Schools: mathematics vs. computer science\n",
    "    - Focus: statistical inference vs. prediction effectiveness\n",
    "    - Methods: formula-based vs. algorithm-based\n",
    "    - Assumptions: strict vs. weak\n",
    "    \n",
    "    \n",
    "Reference: [Difference between Machine Learning & Statistical Modeling, Tavish Srivastava](https://www.analyticsvidhya.com/blog/2015/07/difference-machine-learning-statistical-modeling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (2.2):  Machine Learning Theory: Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1: Two models predict $Y$ with $\\hat{Y}_1 = f_1(X, \\theta_1)$, $\\hat{Y}_2 = f_2(X, \\theta_2)$\n",
    "    - Which model is better for prediction? How to decide?\n",
    "- Loss function $L(Y, \\hat{Y})$: measure the error between true and predicted values, the smaller the better\n",
    "    - Sum of squared errors (L2 dist): $L(Y, \\hat{Y}) = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
    "    - Sum of absolute errors (L1 dist): $L(Y, \\hat{Y}) = \\sum_{i=1}^n|y_i - \\hat{y}_i|$\n",
    "    - Misclassification errors (L0 dist): $L(Y, \\hat{Y}) = \\sum_{i=1}^n1(y_i \\neq \\hat{y}_i)$\n",
    "    - Log loss for binary: $L(Y, \\hat{Y}) = -\\sum_{i=1}^n\\left(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array([0, 0, 1, 1, 1])\n",
    "yhat1 = np.array([0.2, 0.3, 0.6, 0.7, 0.6])\n",
    "yhat2 = np.array([0.1, 0.1, 0.9, 0.8, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108 0.112\n",
      "0.32 0.24\n",
      "0.0 0.2\n",
      "0.391628937345 0.348639580523\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.mean_squared_error(y, yhat1), metrics.mean_squared_error(y, yhat2))\n",
    "print(metrics.mean_absolute_error(y, yhat1), metrics.mean_absolute_error(y, yhat2))\n",
    "print(metrics.zero_one_loss(y, yhat1 > 0.5), metrics.zero_one_loss(y, yhat2 > 0.5))\n",
    "print(metrics.log_loss(y, yhat1), metrics.log_loss(y, yhat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (2.3): Machine Learning Theory: Training-Validation Sets\n",
    "- Q2: How can we know the effectiveness of prediction on data outside sample?\n",
    "- Assumption: Sample are selected from population randomly\n",
    "- Method: Divide our sample randomly into 2 parts: training set and validation set\n",
    "    - Training Set $(X_T, Y_T)$: fitting model $\\hat{\\theta} = \\min_{\\theta\\in\\Theta_f}\\left[L(Y_T, \\hat{Y}_T) + \\lambda P(\\theta)\\right]$\n",
    "    - Validation Set $(X_V, Y_V)$: estimating prediction error $L(Y_V, \\hat{Y}_V)$ from trained $\\hat{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 4235, 43628, 15061, 21764, 48000,  1633, 40517, 33546, 18197,\n",
       "            42314,\n",
       "            ...\n",
       "            38042,  7496, 52841, 14709, 45641, 30070, 48503, 18090, 24104,\n",
       "            41809],\n",
       "           dtype='int64', name='n', length=10000)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly choose 5000 from index as validation set\n",
    "np.random.seed(1)\n",
    "ir_v = ir_lab[np.random.choice(len(ir_lab), 10000, replace=False)]\n",
    "ir_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    2,     4,     9,    10,    11,    12,    14,    17,    22,\n",
       "               25,\n",
       "            ...\n",
       "            53923, 53926, 53928, 53929, 53931, 53932, 53933, 53935, 53936,\n",
       "            53937],\n",
       "           dtype='int64', name='n', length=29708)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use other labeled index as training set\n",
    "ir_t = ir_lab.difference(ir_v) \n",
    "ir_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (2.4): Machine Learning Theory: Cross Validation\n",
    "- Q4: How about the unused validation set?\n",
    "- Cross-validation (CV): \n",
    "    1. Divide data $(X, Y)$ into $K$ parts $(X_{(1)}, Y_{(1)}), \\cdots, (X_{(K)}, Y_{(K)})$\n",
    "    2. Each time $i$, select $(X_{(i)}, Y_{(i)})$ as validation set, leaving other parts as training set, train a model and calculate the validation error.\n",
    "    3. For $i = 1,2,\\cdots K$, repeat step 2 and get $K$ models and $K$ validation errors, use mean validation errors to estimate the prediction of model\n",
    "    4. For prediction of new data $X_{new}$, use the $K$ trained models to predict $\\hat{Y}_{new(1)}, \\cdots, \\hat{Y}_{new(K)}$, and calculate the mean $\\hat{Y}_{new}$ as final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7942 [14673 10420 11790 ..., 48024 23835 18769]\n",
      "7942 [20486  5161 46840 ..., 28921 18522 10678]\n",
      "7942 [20494 36719 12989 ..., 37943 52551 45799]\n",
      "7941 [49427 13106 17213 ..., 41469 19461 48675]\n",
      "7941 [43461 29647  7927 ..., 24176 38142 21401]\n"
     ]
    }
   ],
   "source": [
    "# Randomly split index equally into k = 5 folds\n",
    "np.random.seed(123)\n",
    "cvfold = np.array_split(np.random.permutation(ir_lab), 5)\n",
    "for ir_v in cvfold:\n",
    "    print(len(ir_v), ir_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7942,), (31766,))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select fold 0 as validation set, leaving others as training set\n",
    "ir_v = cvfold[0]\n",
    "ir_t = np.concatenate(np.delete(cvfold, 0))\n",
    "ir_v.shape, ir_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (3): An Example for CV Training: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will show how to compile cross-validation procedures with scikit-learn models\n",
    "- In the next, we will build an extendable machine learning system step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (3.1): Single Model Training\n",
    "\n",
    "Commonly-used procedure for scikit-learn models:\n",
    "1. create a sklearn model with initiation parameters: `model = MODEL_FUNCTION(...)` \n",
    "2. Fit model with training data: `model.fit(X, Y)`\n",
    "3. Transform/predict validation data with same columns: `model.transform(X_new)`, or `model.predict(X_new)`\n",
    "4. Check important model attributes (coefficients of model, feature importance, ...)\n",
    "5. Evaluate the loss of prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31766, 30), (7942, 30), (31766,), (7942,))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split X and Y with training-validation index\n",
    "X_t = X.loc[ir_t]\n",
    "X_v = X.loc[ir_v]\n",
    "Y_t = Y.loc[ir_t]\n",
    "Y_v = Y.loc[ir_v]\n",
    "X_t.shape, X_v.shape, Y_t.shape, Y_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a linear model in scikit-learn\n",
    "from sklearn import linear_model\n",
    "model_lm = linear_model.LinearRegression()\n",
    "model_lm.fit(X_t, Y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.061e+03,   3.947e-01,  -2.135e+01,  -1.455e+02,  -1.208e+02,\n",
       "        -1.623e+03,   1.530e+03,   1.039e+01,   2.596e+02,  -1.813e+02,\n",
       "         8.355e+02,   3.791e+02,  -9.727e+02,   6.111e+01,   2.261e+02,\n",
       "         1.411e+02,   1.412e+02,  -7.363e+01,  -9.083e+01,  -1.902e+02,\n",
       "        -3.503e+02,  -4.466e+02,  -5.144e+02,   9.231e+02,   1.499e+03,\n",
       "         9.615e+02,   1.576e+03,   1.710e+03,   1.218e+03,   1.387e+03])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients of the model\n",
    "model_lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6384.359,  4841.293,  5646.837, ...,  2334.886,  8499.037,\n",
       "        6406.842])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on traing-validation set\n",
    "Yhat_t = model_lm.predict(X_t)\n",
    "Yhat_v = model_lm.predict(X_v)\n",
    "Yhat_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195453.11865 1124230.24602\n"
     ]
    }
   ],
   "source": [
    "# Measure the training-validation loss\n",
    "print(metrics.mean_squared_error(Y_t, Yhat_t), metrics.mean_squared_error(Y_v, Yhat_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (3.2): Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: LinearRegression, training / validation loss of 1195453.1187 / 1124230.2460, time: 0.02s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: LinearRegression, training / validation loss of 1173425.1747 / 1216519.3269, time: 0.02s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: LinearRegression, training / validation loss of 1151868.3602 / 31732262.8501, time: 0.02s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: LinearRegression, training / validation loss of 1153809.0552 / 2033567.7364, time: 0.02s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: LinearRegression, training / validation loss of 1162905.5278 / 1263047.8782, time: 0.02s\n"
     ]
    }
   ],
   "source": [
    "model_L = []\n",
    "for i_cv, ir_v in enumerate(cvfold):\n",
    "    ir_t = np.concatenate(np.delete(cvfold, i_cv))\n",
    "    print(\"CV fold: {} / {}, training / validation sample: {} / {}\".format(i_cv, len(cvfold), len(ir_t), len(ir_v)))\n",
    "    X_t, X_v = X.loc[ir_t], X.loc[ir_v]\n",
    "    Y_t, Y_v = Y.loc[ir_t], Y.loc[ir_v]\n",
    "    time_start = time.time()\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_t, Y_t)\n",
    "    Yhat_t = model.predict(X_t)\n",
    "    Yhat_v = model.predict(X_v)\n",
    "    loss_t = metrics.mean_squared_error(Y_t, Yhat_t)\n",
    "    loss_v = metrics.mean_squared_error(Y_v, Yhat_v)\n",
    "    print(\"    Model: {}, training / validation loss of {:.4f} / {:.4f}, time: {:.2f}s\".format(\n",
    "        model.__class__.__name__, loss_t, loss_v, time.time() - time_start))\n",
    "    model_L.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (3.3): Cross-Validation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14232,), (14232, 30))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the prediction dataset\n",
    "Y_test = da_true.loc[ir_unlab, \"price\"]\n",
    "X_test = X.loc[ir_unlab]\n",
    "Y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, Model: LinearRegression, test loss: 1433637.9177\n",
      "CV fold: 1 / 5, Model: LinearRegression, test loss: 1396212.3983\n",
      "CV fold: 2 / 5, Model: LinearRegression, test loss: 1272658.1702\n",
      "CV fold: 3 / 5, Model: LinearRegression, test loss: 3951809.6878\n",
      "CV fold: 4 / 5, Model: LinearRegression, test loss: 1443855.5761\n"
     ]
    }
   ],
   "source": [
    "Yhat_test_L = []\n",
    "for i, model in enumerate(model_L):\n",
    "    Yhat_test = model.predict(X_test)\n",
    "    loss_test = metrics.mean_squared_error(Y_test, Yhat_test)\n",
    "    print(\"CV fold: {} / {}, Model: {}, test loss: {:.4f}\".format(i, len(model_L), model.__class__.__name__, loss_test))\n",
    "    Yhat_test_L.append(Yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622698.9956051891"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean CV model\n",
    "metrics.mean_squared_error(Y_test, np.mean(Yhat_test_L, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438273.0358240714"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full sample model\n",
    "model_lm = linear_model.LinearRegression()\n",
    "model_lm.fit(X.loc[ir_lab], Y.loc[ir_lab])\n",
    "Yhat_test = model_lm.predict(X_test)\n",
    "metrics.mean_squared_error(Y_test, Yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (4.1): Over-Fitting and Penalty Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To train a machine learning model, when we only $\\min_{\\theta\\in\\Theta_f}L(Y, \\hat{Y})$:\n",
    "\n",
    "- An extremely complex model may always be \"better\" in training set (over-fitting)\n",
    "    - Fit 10,000-order polynomials on $Y$ of sample-size 10,000\n",
    "    - A too complex model may not be true for population out of sample\n",
    "    - A too complex model may be unstable\n",
    "    \n",
    "- Method: find a simpler model $\\hat{\\theta}$ by $\\min_{\\theta\\in\\Theta_f}\\left[L(Y, \\hat{Y}) + \\lambda P(\\theta)\\right]$\n",
    "    - Loss function $L(Y, \\hat{Y})$: control the errors of fitting\n",
    "    - Penalty function $P(\\theta)$: measure the complexity of model\n",
    "        - Ridge (L2 dist): $P(\\beta) = \\sum_{i=1}^p\\beta_i^2$\n",
    "        - Lasso (L1 dist): $P(\\beta) = \\sum_{i=1}^p|\\beta_i|$\n",
    "        - AIC/BIC (L0 dist): $P(\\beta) = \\sum_{i=1}^p1(\\beta_i\\neq 0)$\n",
    "    - Penalty coefficient $\\lambda$: greater $\\lambda \\rightarrow$ simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a335ea160>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIMCAYAAAAKDkGtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XlcVmX+//HXuQEBETVwX0pMQEXhFtxKERByycLMLXOtHMZMW6hf2lBmTS751Sizxmm0XNLcyjHNnFTENRdI3BBRDJNyKZ0Id5Dz+0NiMlxQb7hZ3s/Ho0f3fa7tcy61Pl5c5zqGaZqIiIiIiMjNWewdgIiIiIhIaaHkWURERESkkJQ8i4iIiIgUkpJnEREREZFCUvIsIiIiIlJISp5FRERERApJybOIiIiISCEpeRYRERERKSQlzyIiIiIihaTkWURERESkkBztHcCNVKtWzWzQoEGxj3v27Fnc3NyKfdyySvNpW5pP29Fc2pbm07Y0n7al+bSdsjqXiYmJv5imWf1m9Up08tygQQMSEhKKfdz4+HhCQ0OLfdyySvNpW5pP29Fc2pbm07Y0n7al+bSdsjqXhmEcKUw9bdsQERERESkkJc8iIiIiIoWk5FlEREREpJBK9J5nERERkZIuOzubjIwMLly4YO9QikWVKlXYv3+/vcO4bS4uLtSrVw8nJ6fbaq/kWUREROQOZGRk4O7uToMGDTAMw97hFLmsrCzc3d3tHcZtMU2TU6dOkZGRgZeX1231oW0bIiIiInfgwoULeHp6lovEubQzDANPT887+imBkmcRERGRO6TEufS4018rJc8iIiIicpX09HTmz59v7zBKJCXPIiIiIuVQTk7OdcuUPF+fkmcRERGRUm7OnDn4+/sTEBDAwIEDWb58OW3atKFFixZERERw4sQJAMaOHUtUVBSdOnVi0KBBpKenExwcTGBgIIGBgWzZsgWA0aNHs3HjRqxWK7Gxsfa8tRJHp22IiIiI2Mgby/eR/NNvNu2zaZ3KvP6w33XL9+3bx7hx49i8eTPVqlXj9OnTGIbB1q1bMQyDGTNmMGnSJKZMmQJAYmIimzZtwtXVlXPnzrF69WpcXFw4ePAg/fr1IyEhgYkTJzJ58mRWrFhh03spC5Q8i4iIiJRicXFx9OrVi2rVqgHg4eHBnj176Nu3L8eOHePSpUtXHcsWGRmJq6srcOWM6hEjRpCUlISDgwOpqal2uYfSRMmziIiIiI3caIW4qJimWeAEiZEjRxIdHU1kZCTx8fGMHTs2v8zNzS3/c2xsLDVr1mTXrl3k5ubi4uJSXGGXWtrzLCIiIlKKhYeHs2jRIk6dOgXA6dOnyczMpG7dugDMnj37um0zMzOpXbs2FouFuXPncvnyZQDc3d3Jysoq+uBLISXPIiIiIqWYn58fMTExhISEEBAQQHR0NGPHjqV3794EBwfnb+e4luHDhzN79mzatm1Lampq/qq0v78/jo6OBAQE6IHBP9G2DREREZFSbvDgwQwePPiqa927dy9Q74/bNwC8vb3ZvXt3/vcJEyYA4OTkxNq1a20faBmglWcRERERkUIqdPJsGIaDYRg7DcNYkffdyzCMbYZhHDQMY6FhGBXyrjvnfT+UV97gD328knf9gGEYnW19MyIiIiIiRelWVp6fA/b/4fvbQKxpmt7Af4Gn8q4/BfzXNM1GQGxePQzDaAo8BvgBXYAPDcNwuLPwi4ZpmmRfzrV3GCIiIiJSwhQqeTYMox7QDZiR990AOgJL8qrMBh7J+9w97zt55eF59bsDC0zTvGia5vfAIaC1LW7Cls5fusyz687xr42H7R2KiIiIiJQwhV15fhd4Gfh9OdYT+NU0zd9fip4B1M37XBc4CpBXnplXP//6NdqUGK4VHHBxMNj3o23fDiQiIiIipd9NT9swDOMh4KRpmomGYYT+fvkaVc2blN2ozR/HiwKiAGrWrEl8fPzNQrS5uhVz2ZF23C5jl0VnzpzRXNqQ5tN2NJe2pfm0Lc2nbRXlfFapUqVcnYl8+fLlUn+/Fy5cuO3fD4U5qq4dEGkYxoOAC1CZKyvRVQ3DcMxbXa4H/JRXPwOoD2QYhuEIVAFO/+H67/7YJp9pmh8BHwG0bNnSDA0NvY3bujNfpn1D0sFsAtu2o7KLU7GPX9bEx8djj1/HskrzaTuaS9vSfNqW5tO2inI+9+/fj7u7e5H0fTvGjh1LpUqVeOmll26pXVJSEj/99BMPPvjgDfvJysoqUfd7O1xcXGjRosVttb3ptg3TNF8xTbOeaZoNuPLAX5xpmv2BdUCvvGqDgWV5n7/M+05eeZxpmmbe9cfyTuPwAryB7bcVdRFrUPnKtCT/pK0bIiIiUj4kJSWxcuVKe4dR4t3JOc+jgGjDMA5xZU/zzLzrMwHPvOvRwGgA0zT3AYuAZGAV8IxpmpfvYPwic0/lK4eA7P0x086RiIiIiNzcuHHj8PX1JSIiggMHDgCQlpZGly5dCAoKIjg4mJSUFACGDBnCsGHDCA4OxsfHhxUrVnDp0iXGjBnDwoULsVqtLFy4EIDk5GRCQ0Np2LAhU6dOtdv9lSS39IZB0zTjgfi8z4e5xmkZpmleAHpfp/04YNytBlncqjgb1KzszD6tPIuIiMit+Ho0HN9j2z5rNYeuE69bnJiYyIIFC9i5cyc5OTkEBgYSFBREVFQU06dPx9vbm23btjF8+HDi4uIASE9PZ/369aSlpREWFsahQ4d48803SUhIYNq0acCVbRspKSmsW7eOrKwsfH19efrpp217b6WQXs99Hf71qrL9+9OYpsmVk/ZERERESp6NGzfSo0cPKlasCEBkZCQXLlxgy5Yt9O79v/XMixcv5n/u06cPFosFb29vGjZsmL8q/WfdunXD2dkZZ2dnatSowYkTJ6hSpUrR3lAJp+T5Oh5oWpPVySfYnZFJQP2q9g5HRERESoMbrBAXpT8v9OXm5lK1alWSkpIKVf96C4XOzs75nx0cHMjJyblmvfLkTvY8l2mdm9aigqOFxYlHb15ZRERExE46dOjA0qVLOX/+PFlZWSxfvpyKFSvi5eXF4sWLgStvT961a1d+m8WLF5Obm0taWhqHDx/G19cXd3f3Un8EXXFQ8nwdVSo68VDz2vx750+cvai/ZYmIiEjJFBgYSN++fbFarfTs2ZPg4GAA5s2bx8yZMwkICMDPz49ly5blt/H19SUkJISuXbsyffp0XFxcCAsLIzk5+aoHBqUgbdu4gcfb3M0XO3/kq93H6NOq/s0biIiIiNhBTEwMMTExBa6vWrXqmvXbtWtHbGzsVdc8PDzYsWPHdcfYu3cvQLlfndbK8w0E3XMXDau7sShBWzdERERERCvPN2QYBr2D6vP2qhSOnDrLPZ5u9g5JRERE5I7MmjXL3iGUalp5volHWtTBMGDpzh/tHYqIiIiI2JmS55uoXcWV+xp68vl3GVzONe0djoiIiIjYkZLnQhjY9h6Onj7Pyj3H7B2KiIiIiNiRkudC6ORXi0Y1KjEt7hC5Wn0WERERKbeUPBeCg8VgZMdGHDiRxX/2Hbd3OCIiIiL5fv31Vz788MMb1klPT6dZs2bXLAsNDSUhIaEoQiuTlDwX0kP+dWhYzY2pcYcwTa0+i4iISMlQmORZbEfJcyE5WAyeCWvE/mO/sWb/SXuHIyIiIgLA6NGjSUtLw2q18sILLxAeHk5gYCDNmze/6q2COTk5DB48GH9/f3r16sW5c+cK9PXNN99w3333ERgYSO/evTlz5kxx3kqpoHOeb0F3ax3eW3uQ9+MOEtGkBoZh2DskERERKUHe3v42KadTbNpnY4/GjGo96rrlEydOZO/evSQlJZGTk8O5c+eoXLkyv/zyC23btiUyMhKAAwcOMHPmTNq1a8eTTz7Jhx9+yEsvvZTfzy+//MJbb73FmjVrcHNz4+233+add95hzJgxNr2f0k4rz7fA0cHCM2H3sjsjk/jUn+0djoiIiMhVTNPkb3/7G/7+/kRERPDjjz9y4sQJAOrXr0+7du0AGDBgAJs2bbqq7datW0lOTqZdu3ZYrVZmz57NkSNHiv0eSjqtPN+iHi3qMXXtIWJXpxLqU12rzyIiIpLvRivExWHevHn8/PPPJCYm4uTkRIMGDbhw4QJAgZzlz99N0+SBBx7gs88+K7Z4SyOtPN+iCo4WXnjAh90Zmazco5M3RERExL7c3d3JysoCIDMzkxo1auDk5MS6deuuWjn+4Ycf+PbbbwH47LPPaN++/VX9tG3bls2bN3Po0CEAzp07R2pqajHdRemh5Pk29GhRF9+a7vzff1LIvpxr73BERESkHPP09KRdu3Y0a9aMpKQkEhISaNmyJfPmzaNx48b59Zo0acLs2bPx9/fn9OnTPP3001f1U716dWbNmkW/fv3w9/enbdu2pKTYdv92WaBtG7fBwWIwqqsvT85K4LPtPzDovgb2DklERETKsfnz59+0TnJy8jWvx8fH53/u2LEjO3bssFVYZZJWnm9TmG8N2nh5MHXtQc5czLF3OCIiIiJSDJQ83ybDMHjlwSb8cuYSszZ/b+9wRERERKQYKHm+A9b6VQlvXIN/bfye3y5k2zscERERESliSp7v0AsP+JB5Ppt/xKfZOxQRERERKWJKnu9Qs7pV6NGiLjM3fU/6L2ftHY6IiIiIFCElzzYwumtjnB0sxPx7D6Zp2jscERERESkiSp5toGZlF17u2pjNh06xdOeP9g5HRERE5I6lp6cX6gg8gCFDhrBkyZLbGic+Pp4tW7bYpK/ioOTZRvq3vpsWd1flra/289+zl+wdjoiIiMhN5eRc/7jdW0me78Sfk+eSTsmzjVgsBhMebc5v57OZ8PV+e4cjIiIi5cicOXPw9/cnICCAgQMHArB8+XLatGlDixYtiIiI4MSJEwCMHTuWqKgoOnXqxKBBg0hPTyc4OJjAwEACAwPzE9nRo0ezceNGrFYrsbGxV41nmiYjRoygadOmdOvWjZMnT+aXJSYmEhISQlBQEJ07d+bYsWMAhIaG8vzzz3P//ffTrFkztm/fTnp6OtOnTyc2Nhar1crGjRsB2LBhA/fffz8NGzYscavQesOgDTWuVZmhwQ2Zvj6NnoH1aNPQ094hiYiISDE6Pn48F/fb9pXWzk0aU+tvf7tu+b59+xg3bhybN2+mWrVqnD59GoD27duzdetWDMNgxowZTJo0iSlTpgBXEtxNmzbh6urKuXPnWL16NS4uLhw8eJB+/fqRkJDAxIkTmTx5MitWrCgw5tKlSzlw4AB79uzhxIkTNG3alCeffJLs7GxGjhzJsmXLqF69OgsXLiQmJoaPP/4YgLNnz7JlyxY2bNjAk08+yd69exk2bBiVKlXipZdeAmDmzJkcO3aMTZs2kZKSQmRkJL169bLpnN4JJc829ly4Nyt2/8Tflu5h5XPBODs62DskERERKcPi4uLo1asX1apVA8DDwwOAjIwM+vbty7Fjx7h06RJeXl75bSIjI3F1dQUgOzubESNGkJSUhIODA6mpqTcdc8OGDfTr1w8HBwfq1KlDx44dAThw4AB79+7lgQceAODy5cvUrl07v12/fv0A6NChA7/99hu//vrrNft/5JFHsFgsNG3aNH/FvKRQ8mxjrhUceOuRZgz5ZAcfrT/MyHBve4ckIiIixeRGK8RFxTRNDMMocH3kyJFER0cTGRlJfHw8Y8eOzS9zc3PL/xwbG0vNmjXZtWsXubm5uLi4FGrca41pmiZ+fn58++23hWpzrT4AnJ2dr+qzJNGe5yIQ6luDh/xr8/66Qxz++Yy9wxEREZEyLDw8nEWLFnHq1CmA/G0bmZmZ1K1bF4DZs2dft31mZia1a9fGYrEwd+5cLl++DIC7uztZWVnXbNOhQwcWLFjA5cuXOXbsGOvWrQPA19eXn3/+OT95zs7OZt++ffntFi5cCMCmTZuoUqUKVapUueE4JZGS5yIy5qGmODtaePXfe0vc35hERESk7PDz8yMmJoaQkBACAgKIjo4GrjwY2Lt3b4KDg/O3dFzL8OHDmT17Nm3btiU1NTV/Vdrf3x9HR0cCAgIKPDDYo0cPvL29ad68OU8//TQhISEAVKhQgSVLljBq1CgCAgKwWq1XnaRx1113cf/99zNs2DBmzpwJwMMPP8zSpUuvemCwJNO2jSJSo7ILo7o05tV/72Xpzh95NLCevUMSERGRMmrw4MEMHjz4qmvdu3ene/fuBer+cfsGgLe3N7t3787/PmHCBACcnJxYu3btNcczDINp06Zds8xqtbJhw4ZrlvXs2TO//9/5+PhcNX5wcPBV5WfOlKyf4mvluQg93vpuAnX2s4iIiEiZoeS5CFksBuN19rOIiIgI8fHxtGzZ0t5h3DElz0Xs97OfFyVksPXwKXuHIyIiIiJ3QMlzMXgu3Jv6Hq78bekeLmRftnc4IiIiInKblDwXgytnPzfn8M9n+TA+zd7hiIiIiMhtUvJcTEJ8qvOItQ7/iD9E6onSc5ahiIiIiPyPkudi9NpDTank7Mioz3dzOVdnP4uIiEjJlZ6ezvz582+57I/i4+N56KGHrlnWoEEDfvnllzuK0R6UPBcjz0rOvP6wHzt/+JVPNn9v73BERESknMvJyblumS2S57JIyXMx626tQ0STmkxadYB9P2XaOxwREREpA+bMmYO/vz8BAQEMHDgQgOXLl9OmTRtatGhBREQEJ06cAK68JCUqKopOnToxaNAg0tPTCQ4OJjAwkMDAwPw3Ao4ePZqNGzditVoLvGHwz2XX6wPgt99+o0ePHjRt2pRhw4aRm5tbIP5PP/2U1q1bY7Va+etf/5r/ivCSSG8YLGaGYTCplz9d3t3As5/tZPnI9lSsoF8GERGRsmDjolR+OWrbN+JVq1+J4D4+1y3ft28f48aNY/PmzVSrVo3Tp08D0L59e7Zu3YphGMyYMYNJkyYxZcoUABITE9m0aROurq6cO3eO1atX4+LiwsGDB+nXrx8JCQlMnDiRyZMns2LFigJj/rnsen0AbN++neTkZO655x66dOnCF198Qa9evfL72r9/PwsXLmTz5s04OTkxfPhw5s2bx6BBg2w2h7akrM0OPNwq8E4fKwM/3sYrX+zh3b5WDMOwd1giIiJSCsXFxdGrVy+qVasGgIeHBwAZGRn07duXY8eOcenSJby8vPLbREZG4urqCkB2djYjRowgKSkJBwcHUlNTbzmGG/XRunVrGjZsCEC/fv3YtGnTVcnz2rVrSUxMpFWrVgCcP3+eGjVq3HIMxUXJs520965GdIQPU1an4l+vKk+197p5IxERESnRbrRCXFRM07zmItzIkSOJjo4mMjKS+Ph4xo4dm1/m5uaW/zk2NpaaNWuya9cucnNzcXFxueUYbtTHn2P783fTNBk8eDATJky45XHtQXue7eiZsEZ0alqT8Sv3syH1Z3uHIyIiIqVQeHg4ixYt4tSpK28y/n3bRmZmJnXr1gVg9uzZ122fmZlJ7dq1sVgszJ07N3+/sbu7O1lZ1z5e989l1+sDrmzb+P7778nNzWXhwoW0b9++QPxLlizh5MmT+fEfOXLkVqeh2Ch5tiOLxeCdvla8a1Ri+LzvSP7pN3uHJCIiIqWMn58fMTExhISEEBAQQHR0NHDlwcDevXsTHBycv6XjWoYPH87s2bNp27Ytqamp+avS/v7+ODo6EhAQUOCBwT+XXa8PgPvuu4/Ro0fTrFkzvLy86NGjx1V9NW3alLfeeotOnTrh7+/PAw88wLFjx2w1PTZnmGbJPW+4ZcuW5u+bzYtTfHw8oaGhxTbesczz9PjgylOpS5+5n9pVXItt7OJQ3PNZ1mk+bUdzaVuaT9vSfNpWUc7n/v37adKkSZH0XRJlZWXh7u5u7zDuyLV+zQzDSDRNs+XN2mrluQSoXcWVj4e04szFHJ74ZAe/Xci2d0giIiIicg1KnkuIpnUqM31AEIdOnmHY3EQu5RQ8A1FERERE7EvJcwnS3rsak3r5syXtFM9+tpPsy0qgRUREREoSJc8lzKOB9RjzUFNW7TvOCwuTyFECLSIiIlJi6JznEujJ9l7k5OYyfmUKJvBOnwCcHR3sHZaIiIhIuafkuYSK6nAvAONXpnDytwv8c2BLPNwq2DkqERERkfJN2zZKsKgO9/J+vxbsysjk0Q83c/DEtQ8qFxEREbG19PR05s+fb+8wShwlzyXcwwF1+OwvbThzMYfIaZv5PDHD3iGJiIhIGZGTk3PdMiXP16bkuRQIuseDr54Nxr9eFV5cvIuXl+zi/KXLN28oIiIi5cKcOXPw9/cnICCAgQMHArB8+XLatGlDixYtiIiI4MSJE8CVNw9GRUXRqVMnBg0aRHp6OsHBwQQGBhIYGMiWLVde3DZ69Gg2btyI1Wot8IbBpUuXEhERgWmaHDt2DB8fH44fP168N20n2vNcStSs7MK8oW14b+1Bpq07xK6jmXzQP5BGNSrZOzQRERHJs27WR5w8ctimfda4pyFhQ6KuW75v3z7GjRvH5s2bqVatGqdPnwagffv2bN26FcMwmDFjBpMmTWLKlCkAJCYmsmnTJlxdXTl37hyrV6/GxcWFgwcP0q9fPxISEpg4cSKTJ09mxYoVBcbs0aMHn3/+OR988AGrVq3ijTfeoFatWja975JKyXMp4uhg4cVOvrRq4MHzC5OInLaJ8T2a80iLuvYOTUREROwkLi6OXr16Ua1aNQA8PDwAyMjIoG/fvhw7doxLly7h5eWV3yYyMhJXV1cAsrOzGTFiBElJSTg4OJCamlqocd9//32aNWtG27Zt6devn43vquRS8lwKdfCpzspng3n2s508vzCJbd+f4vWH/XBx0nF2IiIi9nSjFeKiYpomhmEUuD5y5Eiio6OJjIwkPj6esWPH5pe5ubnlf46NjaVmzZrs2rWL3NxcXFxcCjXujz/+iMVi4cSJE+Tm5mKxlI/dwOXjLsugWlVcmP+XNjwdei+fbT9Kjw+3cPjnM/YOS0RERIpZeHg4ixYt4tSpUwD52zYyMzOpW/fKT6dnz5593faZmZnUrl0bi8XC3LlzuXz5ynNV7u7uZGVd+6SvnJwcnnjiCebPn0+TJk145513bHlLJZqS51LM0cHCqC6N+eSJVhzPPM/D729iSWIGpmnaOzQREREpJn5+fsTExBASEkJAQADR0dHAlQcDe/fuTXBwcP6WjmsZPnw4s2fPpm3btqSmpuavSvv7++Po6EhAQECBBwbHjx9PcHAwwcHBvPPOO8yYMYP9+/cX3U2WINq2UQaE+dbgq2eDeX5hEi8t3sWG1J95q0czKrs42Ts0ERERKQaDBw9m8ODBV13r3r073bt3L1D3j9s3ALy9vdm9e3f+9wkTJgDg5OTE2rVrrznemDFj8j+7u7uTkpJyu6GXOlp5LiPqVHXls7+05aVOPny15xgPvreRzYd+sXdYIiIiImWKkucyxMFiMKKjN4uH3YejxaD/jG1EL0ri1JmL9g5NREREpExQ8lwGBd59F6ue78CIsEYs3/UT4e+sZ1HCUe2FFhEREblDSp7LKBcnB17q7MtXzwbjXaMSLy/ZzWMfbeXQSZ3IISIiInK7lDyXcT413VkYdR8TH23O/mO/8eB7G3lndSoXsvV6bxEREZFbpeS5HLBYDB5rfTdrXwzlwea1mLr2IF3f28iG1J/tHZqIiIhIqaLkuRyp7u7Mu4+1YO5TrQEY9PF2npn/HcczL9g5MhERESlp0tPTmT9/vr3DKHGUPJdDwd7VWfV8MC8+4MOa5BOET4lnWtxBfs7SqRwiIiLlSU5OznXLlDxfm5LncsrZ0YGR4d6sfiGEtg09mfxNKvdNWMuwuYmsO3CSy7k6mUNERKS0mDNnDv7+/gQEBDBw4EAAli9fTps2bWjRogURERGcOHECuPKSlKioKDp16sSgQYNIT08nODiYwMBAAgMD2bJlCwCjR49m48aNWK3WAm8YHDhwIMuWLcv/3r9/f7788stiulv70hsGy7m7PSsyc0grDp08w6KEo3yemMGqfcepU8WFXi3r06dlPerdVdHeYYqIiJQKvy5P49JPZ23aZ4U6blR9+N7rlu/bt49x48axefNmqlWrxunTpwFo3749W7duxTAMZsyYwaRJk5gyZQoAiYmJbNq0CVdXV86dO8fq1atxcXHh4MGD9OvXj4SEBCZOnMjkyZNZsWJFgTGHDh1KbGws3bt3JzMzky1btjB79myb3ndJpeRZAGhUoxJ/e7AJL3XyZc3+E3y2/QfejzvI+3EHCfauTr9W9QlvUpMKjvphhYiISEkSFxdHr169qFatGgAeHh4AZGRk0LdvX44dO8alS5fw8vLKbxMZGYmrqysA2dnZjBgxgqSkJBwcHEhNTb3pmCEhITzzzDOcPHmSL774gp49e+LoWD7SyvJxl1JoFRwtPNi8Ng82r83R0+dYnJjB4oSjPD3vOzzdKtAzqB59W9Xn3uqV7B2qiIhIiXOjFeKiYpomhmEUuD5y5Eiio6OJjIwkPj6esWPH5pe5ubnlf46NjaVmzZrs2rWL3NxcXFxcCjXuwIEDmTdvHgsWLODjjz++4/soLbSMKNdV36Mi0Q/4sGlURz4Z0oqWDe7i403fEz5lPX2mf8vniRmcv6TzokVEROwpPDycRYsWcerUKYD8bRuZmZnUrVsX4IZbKjIzM6lduzYWi4W5c+dy+fKV/7e7u7uTlZV13XZDhgzh3XffBcDPz88m91IaKHmWm3KwGIQ1rsE/B7ZkyysdGdWlMSezLvDi4l20Hr+G1/69l70/Zto7TBERkXLJz8+PmJgYQkJCCAgIIDo6GrjyYGDv3r0JDg7O39JxLcOHD2f27Nm0bduW1NTU/FVpf39/HB0dCQgIKPDAIEDNmjVp0qQJTzzxRNHcWAmlbRtyS2q4u/B06L0MC2nI1sOnWbjjBxYmHGXu1iM0r1uFvq3q091aB3cXJ3uHKiIiUm4MHjyYwYMHX3Wte/fudO/evUDdP27fAPD29mb37t353ydMmACAk5MTa9euve6Y586dy3/AsDzRyrPcFsMwuO9eT959rAU7/hbB2Iebkn05l1f/vZfW49by0uJdJKSfxjR15J2IiEhZs2ZHhXpzAAAgAElEQVTNGho3bszIkSOpUqWKvcMpVlp5ljtWpaITQ9p5Mfj+BuzOyGTBjh/4MuknliRm0KhGJVrelU3zlhfxrORs71BFRETEBiIiIvjhhx/sHYZdKHkWmzEMg4D6VQmoX5VXuzXlq93H+GzHDyw4cIbPJ6ylk18tHmtVn3b3VsNiKfhUsIiIiEhJp+RZioSbsyN9WtWnT6v6fLo8jsPU4oudGXy1+xj17nKlb8v69G5Zn1pVCnccjoiIiEhJoORZilw9dwsDQpvychdfvkk+wYLtPzBldSqxa1IJ861B31b16di4Bo4O2oIvIiIiJZuSZyk2Lk4ORAbUITKgDkdOnWVRwlEWJ2SwNuUkNdyd6d2yHo+1upv6HnoduIiIiJRMWuoTu7jH043/17kxW0Z35F+DWtK8bhX+EZ9G8KR1DJixjRW7f+JSTq69wxQRESl1xo4dy+TJk2+rbVJSEitXrrzlvsaPH1+o/itVuvYbiocMGcKSJUsKF6SdKXkWu3J0sPBA05rMHNKKzaM78kKED9//cpYR83fSdsJaxq/cz+Gfz9g7TBERkXLhz8lzYRU2eS4LlDxLiVG7iivPRXiz4eUwZj3RitYNPPh40/d0nLKexz76li93/cTFHL0OXERE5M/GjRuHr68vERERHDhwIP96WloaXbp0ISgoiODgYFJSUoArK73Dhg0jODgYHx8fVqxYwaVLlxgzZgwLFy7EarWycOFCAJKTkwkNDaVhw4ZMnTq1wNijR4/m/PnzWK1W+vfvD8AjjzxCUFAQfn5+fPTRR1fVf/HFFwkMDCQ8PJyff/65QH+JiYmEhIQQFBRE586dOXbsmM3myRa051lKHAeLQahvDUJ9a3Ay6wKLEzJYsOMHnv1sJx5uFegVVI/HWtWnYfVr/+hHRETEXr7++muOHz9u0z5r1apF165dr1uemJjIggUL2LlzJzk5OQQGBhIUFARAVFQU06dPx9vbm23btjF8+HDi4uIASE9PZ/369aSlpREWFsahQ4d48803SUhIYNq0acCVbRspKSmsW7eOrKwsfH19GTBgwFXjT5w4kWnTppGUlJR/7eOPP8bDw4Pz58/TqlUrevbsiaenJ2fPniUwMJApU6bw5ptv8sYbb+SPBZCdnc3IkSNZtmwZ1atXZ+HChcTExPDxxx/bbD7v1E2TZ8MwXIANgHNe/SWmab5uGIYXsADwAL4DBpqmeckwDGdgDhAEnAL6mqaZntfXK8BTwGXgWdM0/2P7W5KypIa7C8+ENeLpkHvZdOgXPtv+Ax9v+p6PNhymbUMPno/woW1DT3uHKSIiYjcbN26kR48eVKx45YH7yMhIAM6cOcOWLVvo3bt3ft2LFy/mf+7Tpw8WiwVvb28aNmyYvyr9Z926dcPZ2RlnZ2dq1KjByZMn8fDwuGFMU6dOZenSpQAcPXqUgwcP4unpicVioW/fvgAMGDCARx999Kp2Bw4cYO/evTzwwAMAXL58mdq1a9/KdBS5wqw8XwQ6mqZ5xjAMJ2CTYRhfA9FArGmaCwzDmM6VpPgfef/+r2majQzDeAx4G+hrGEZT4DHAD6gDrDEMw8c0Tf0cXm7KYjHo4FOdDj7V81ejP916hMc+2kpkQB1iujWhZmWdGS0iIvZ1oxXiomQYBV8+lpubS9WqVa9aEb5Rm2v1AeDs/L83BDs4OJCTk3PDWOLj41mzZg3ffvstFStWJDQ0lAsXLhQqBtM08fPz49tvv73hGPZ00z3P5hW/P7HllPePCXQEfn8scjbwSN7n7nnfySsPN67MTHdggWmaF03T/B44BLS2yV1IufL7anTci6E8G+7Nqn3H6Tg5no82pOmEDhERKXc6dOjA0qVLOX/+PFlZWSxfvhyAypUr4+XlxeLFi4EriemuXbvy2y1evJjc3FzS0tI4fPgwvr6+uLu7k5WVdcsxODk5kZ2dDUBmZiZ33XUXFStWJCUlha1bt+bXy83NzT9VY/78+bRv3/6qfnx9ffn555/zk+fs7Gz27dt3y/EUpUI9MGgYhoNhGEnASWA1kAb8aprm73/1yADq5n2uCxwFyCvPBDz/eP0abURumWsFB6If8GH1Cx24715Pxq9Moet7G9h86Bd7hyYiIlJsAgMD6du3L1arlZ49exIcHJxfNm/ePGbOnElAQAB+fn4sW7Ysv8zX15eQkBC6du3K9OnTcXFxISwsjOTk5KseGCyMqKgo/P396d+/P126dCEnJwd/f39ee+012rZtm1/Pzc2Nffv2ERQURFxcHGPGjLmqnwoVKrBkyRJGjRpFQEAAVquVLVu23MHs2J5hmmbhKxtGVWApMAb4xDTNRnnX6wMrTdNsbhjGPqCzaZoZeWVpXFlhfhP41jTNT/Ouz8xr8/mfxogCogBq1qwZtGDBgju8xVt35syZ655DKLeuuOYz6WQO81MucfKcScuaDvRrXAFP17J3oIx+f9qO5tK2NJ+2pfm0raKczypVqtCoUaMi6buoDBs2jC5duvDII4/cvPKfXL58GQcHhyKIqvgcOnSIzMzMq66FhYUlmqbZ8mZtb+m0DdM0fzUMIx5oC1Q1DMMxb3W5HvBTXrUMoD6QYRiGI1AFOP2H67/7Y5s/jvER8BFAy5YtzdDQ0FsJ0Sbi4+Oxx7hlVXHNZygwLPsy/9pwmA/iD/HqlkuM6NiIocFeODuW7j/kf6Tfn7ajubQtzadtaT5tqyjnc//+/bi7uxdJ30XFyckJV1fX24o7Kyur1N3vn7m4uNCiRYvbanvTZTnDMKrnrThjGIYrEAHsB9YBvfKqDQZ+/znAl3nfySuPM68sb38JPGYYhnPeSR3ewPbbilrkOlycHBgZ7s2a6BBCfavzf/85QOfYDaw7cNLeoYmIiJQYs2bNolevXjevKAUU5mfatYF1hmHsBnYAq03TXAGMAqINwzjElT3NM/PqzwQ8865HA6MBTNPcBywCkoFVwDM6aUOKSr27KvKPAUHMebI1FovBE5/sYOjsBH44dc7eoYmIiEgpdtNtG6Zp7gYKrGubpnmYa5yWYZrmBaD3n6/nlY0Dxt16mCK3p4NPdVY914GPN3/P1LUHiYhdz9Mh9/J06L24OJWdrRwiIiJSPMre01Qif1LB0cKwkHuJezGULn61eG/tQSLeWc83+45zKw/MioiIiCh5lnKjVhUXpvZrwWd/aUvFCg5EzU1kyCc7+P6Xs/YOTUREREoJJc9S7tx3rydfPRvMaw815bsj/6Vz7AYmrUrh3KUbvzFJRESkNBg7diyTJ0++rbZJSUmsXLnSJn2VVUqepVxycrDwVHsv1r4UwkMBtfkwPo3wKev5avcxbeUQEZFy68/JsxSk5FnKtRruLrzTx8qSYfdxV8UKPDP/OwbM3Mahk7f+alIRERF7GTduHL6+vkRERHDgwIH862lpaXTp0oWgoCCCg4NJSUkBYMiQIQwbNozg4GB8fHxYsWIFly5dYsyYMSxcuPCqNwwmJycTGhpKw4YNmTp1aoGxZ86cyQsvvJD//V//+hfR0dFFfMf2c0svSREpq1o28GD5yPbM33aE//vPAbq8u5En23vxbLg3lZz1x0RERAonNfXvZJ3Zb9M+3Ss1wcfnteuWJyYmsmDBAnbu3ElOTg6BgYEEBQUBV16bPX36dLy9vdm2bRvDhw8nLi4OgPT0dNavX09aWhphYWEcOnSIN998k4SEBKZNmwZc2baRkpLCunXryMrKwtfXlwEDBlw1/mOPPYa/vz+TJk3CycmJTz75hH/+8582nYOSRFmBSB4Hi8HA+xrwYPPa/N9/DvCvjYf5984f+duDTehurYNhGPYOUUREpICNGzfSo0cPKlasCEBkZCRw5ZXkW7ZsoXfv/50gfPHixfzPffr0wWKx4O3tTcOGDfNXpf+sW7duODs74+zsTI0aNTh58iQeHh755W5ubnTs2JEVK1bQpEkTsrOzad68eVHcaomg5FnkTzwrOTOxpz+Ptb6bMcv28vzCJOZv+4E3uvvRpHZle4cnIiIl2I1WiIvStRZ4cnNzqVq1KklJSYVqc71FImdn5/zPDg4O5OQUfMB+6NChjB8/nsaNG/PEE0/cSuiljvY8i1yHtX5V/j28HRMfbc7Bk1k89P4mxn65j8zz2fYOTUREJF+HDh1YunQp58+fJysri+XLlwNQuXJlvLy8WLx4MQCmabJr1678dosXLyY3N5e0tDQOHz6Mr68v7u7uZGXd+nM/bdq04ejRo8yfP59+/frZ5sZKKCXPIjdgsRg81vpu1r0USr/W9Zn9bTodJ8ezKOEoubk6lUNEROwvMDCQvn37YrVa6dmzJ8HBwfll8+bNY+bMmQQEBODn58eyZcvyy3x9fQkJCaFr165Mnz4dFxcXwsLCSE5OvuqBwcLq06cP7dq146677rLZvZVE2rYhUghVK1bgrUea81irK1s5Xl6ym8+2/8Cbkc1oXq+KvcMTEZFyLiYmhpiYmALXvby8WLVq1TXbtGvXjtjY2KuueXh4sGPHjuuOs3fv3uuuTG/atOmqUzfKKq08i9yCZnWrsGTY/UzuHcDR0+eI/GATMUv38N+zl+wdmoiIiF38+uuv+Pj44OrqSnh4uL3DKXJaeRa5RRaLQa+genTyq0ns6lTmfHuEr/Yc4/919uWxVnfjYNGpHCIiUrLNmjXLZn1VrVqV1NRUm/VX0mnlWeQ2VXZx4vWH/fjq2fb41HQnZuleHvlgM9/98F97hyYiIiJFRMmzyB1qXKsyC6Pa8t5jVk5mXeDRD7fw8pJd/HLm4s0bi4iISKmi5FnEBgzDoLu1LmtfDOWvHRryxXc/0nFyPLO3pJNzOdfe4YmIiIiNKHkWsaFKzo688mATVj3fAf96VXn9y3089P4mtn9/2t6hiYiIiA0oeRYpAo1qVGLuU635R/9AfjufTZ9/fssLC5M4+dsFe4cmIiJl3NixY5k8efJttU1KSmLlypU26ausUvIsUkQMw6Br89qseTGEEWGN+Gr3MTpOWc+MjYfJ1lYOEREpgf6cPEtBSp5FiljFCo681NmXb17oQKsGd/HWV/t58L2NbEn7xd6hiYhIGTFu3Dh8fX2JiIjgwIED+dfT0tLo0qULQUFBBAcHk5KSAsCQIUMYNmwYwcHB+Pj4sGLFCi5dusSYMWNYuHDhVW8YTE5OJjQ0lIYNGzJ16tQCY3/55ZdYrVasViu+vr54eXkVz03bic55FikmDaq58fGQVqzdf5I3Vuzj8X9to5t/bV7t1oTaVVztHZ6IiNjAawcz2HvmvE37bFbJlb9717tueWJiIgsWLGDnzp3k5OQQGBhIUFAQAFFRUUyfPh1vb2+2bdvG8OHDiYuLAyA9PZ3169eTlpZGWFgYhw4d4s033yQhIYFp06YBV7ZtpKSksG7dOrKysvD19WXAgAFXjR8ZGUlkZCRw5RXdISEhNr3/kkbJs0gxMgyDiKY1ae9djX+uP8yH8YeI23+SkeGNeKq9F86ODvYOUURESpmNGzfSo0cPKlasCJCfyJ45c4YtW7bQu3fv/LoXL/7vGNU+ffpgsVjw9vamYcOG+avSf9atWzecnZ1xdnamRo0anDx5Eg8PjwL1Jk2ahKurK88884wtb6/EUfIsYgcuTg48F+HNo4F1+fuKZCatOsCShAxej/QjxKe6vcMTEZHbdKMV4qJkGAXfbpubm0vVqlVJSkoqVJtr9QHg7Oyc/9nBwYGcnJwCddauXcvixYvZsGHDrYRdKmnPs4gd1feoyEeDWjLriVaYwOCPtxM1J4Gjp8/ZOzQRESklOnTowNKlSzl//jxZWVksX74cgMqVK+Pl5cXixYsBME2TXbt25bdbvHgxubm5pKWlcfjwYXx9fXF3dycrK+uWxj9y5AjDhw9n0aJFuLqW/W2ISp5FSoBQ3xqsej6Yl7v4svHgL0S8s5731hzkQvZle4cmIiIlXGBgIH379sVqtdKzZ0+Cg4Pzy+bNm8fMmTMJCAjAz8+PZcuW5Zf5+voSEhJC165dmT59Oi4uLoSFhZGcnHzVA4M3M2vWLE6dOkWPHj2wWq08+OCDNr/HkkTbNkRKCGdHB4aHNuIRa13GrdxP7JpUPv8ugzEPNSWiaU17hyciIiVYTEwMMTExBa57eXmxatWqa7Zp164dsbGxV13z8PBgx44d1x1n7969BVamX3/9dV5//fXbiLp00sqzSAlTp6orHzweyPyhbXB2tDB0TgJPztpB+i9n7R2aiIhIuaeVZ5ES6v5G1Vj5XDCzt6Tz7pqDdIrdQFSHhjR3NO0dmoiIlHKzZs2ydwillpJnkRLMycHC0OCGRAbUYcLXKUxbdwhPF4PcGsfo0qzWdZ+MFhERkaKhbRsipUCNyi7E9rWy6K/3UdHJ4Ol53zHo4+0cOnnG3qGJiIiUK0qeRUqR1l4ejL3PhbEPNyXp6K90eXcDE1bu58zFgmduioiIiO0peRYpZRwsBkPaebHupVAeDazLPzccJnxKPF/u+gnT1H5oERGRoqTkWaSUqlbJmUm9Avhi+P1Ud3fm2c920u9fWzlw/NYOtxcREZHCU/IsUsoF3n0Xy55pz7gezUg5nsWDUzfy5vJkfruQbe/QREREyhwlzyJlgIPFoH+be1j3Yih9Wtbnky3f03Hyej5PzCA3V1s5RETKsh07duDv78+FCxc4e/Ysfn5+7N2796o6r732Gu+9917+95iYGKZOnVrcoZYJOqpOpAy5y60CEx5tTr/W9RmzbB8vLt7F/O0/8GZ3P/zqVLF3eCIiZd4by/eR/NNvNu2zaZ3KvP6w33XLW7VqRWRkJK+++irnz59nwIABNGvW7Ko6Tz31FI8++ijPPfccubm5LFiwgO3bt9s0zvJCybNIGeRfrypfPH0/S77L4O2vU3j4/U30b3MPL3byoWrFCvYOT0REbGzMmDG0atUKFxeXa64oN2jQAE9PT3bu3MmJEydo0aIFnp6edoi09FPyLFJGWSwGfVrWp3PTWsSuSWXOt+l8tecYL3f2pU/L+lgsesGKiIit3WiFuCidPn2aM2fOkJ2dzYULF3BzcytQZ+jQocyaNYvjx4/z5JNP2iHKskF7nkXKuCoVnRgb6ceKkcE0ql6J0V/soceHm9l19Fd7hyYiIjYSFRXF3//+d/r378+oUaOuWadHjx6sWrWKHTt20Llz52KOsOzQyrNIOdG0TmUW/rUty5J+YtzK/Tzy4Wb6tqzPy10a4+GmrRwiIqXVnDlzcHR05PHHH+fy5cvcf//9xMXF0bFjx6vqVahQgbCwMKpWrYqDg4Odoi39lDyLlCOGYfBIi7qEN6nB1LUH+WRzOl/vPc5LnXx4vM09OGgrh4hIqTNo0CAGDRoEgIODA9u2bbtmvdzcXLZu3crixYuLM7wyR9s2RMohdxcnYro15evngvGrU5nXlu3j4fc3kXjktL1DExGRIpCcnEyjRo0IDw/H29vb3uGUalp5FinHvGu6M29oG1buOc5bXyXT8x/f8mhgXV7p2oTq7s72Dk9ERGykadOmHD582N5hlAlaeRYp5wzDoJt/bda+GMLw0HtZvusnOk6O5+NN35NzOdfe4YmIiJQoSp5FBICKFRx5uUtj/vN8BwLvuYs3VyTTbeomth4+Ze/QRERESgwlzyJylYbVKzHriVZ8NDCIs5dyeOyjrTz72U6OZ16wd2giIiJ2p+RZRAowDINOfrVYEx3Cc+HerNp3nPAp8fxzfRqXcrSVQ0REyi8lzyJyXS5ODrzwgA9rXgjhvnurMeHrFLq8t4GNB3+2d2giIiJ2oeRZRG7qbs+KzBjckk+GtOJyrsnAmdt5+tNEfvz1vL1DExERKVZKnkWk0MIa1+A/z3fg/3X2Zd2Bk4RPiWda3EEu5ly2d2giIuXWjh078Pf358KFC5w9exY/Pz/27t17VZ3p06djtVqxWq14eXkRFhZmp2hLP53zLCK3xMXJgWfCGvFIi7qM+yqZyd+ksiQxg9cf9iOscQ17hyciYl9fj4bje2zbZ63m0HXidYtbtWpFZGQkr776KufPn2fAgAE0a9bsqjrDhg1j2LBhZGdn07FjR6Kjo20bYzmilWcRuS11q7ryYf8g5j7VGgeLwROzdjB09g5+OHXO3qGJiJQ7Y8aMYfXq1SQkJPDyyy9ft95zzz1Hx44defjhh4sxurJFK88ickeCvavz9XMdmLXle95bc5CI2PUMC7mX4aH34uLkYO/wRESK1w1WiIvS6dOnOXPmDNnZ2Vy4cAE3N7cCdWbNmsWRI0eYNm2aHSIsO7TyLCJ3rIKjhagO97L2xVC6NqvF1LUHiXhnPf/ZdxzTNO0dnohImRcVFcXf//53+vfvz6hRowqUJyYmMnnyZD799FMsFqV/d0KzJyI2U6uKC+891oIFUW1xq+DIX+cmMuSTHRz++Yy9QxMRKbPmzJmDo6Mjjz/+OKNHj2bHjh3ExcVdVWfatGmcPn2asLAwrFYrQ4cOtVO0pZ+2bYiIzbVt6MmKZ9sz99sjxK5OpfO7Gxga3JARYY1wc9Z/dkREbGnQoEEMGjQIAAcHB7Zt21agzieffFLcYZVZWnkWkSLh5GDhyfZexL0USmRAXf4Rn0bEO+tZsfsnbeUQEZFSS8mziBSp6u7OTOkTwOdP34eHWwVGzN9J/xnbOHgiy96hiYiI3DIlzyJSLILu8eDLEe35+yPN2PfTb3R9byNvrUgm60K2vUMTEREpNCXPIlJsHCwGA9vew7qXQundsh4zN39PxynrWbozQ1s5RESkVFDyLCLFzsOtAhMe9effw9tRp6orLyzcRZ9/fkvyT7/ZOzQREZEbUvIsInYTUL8qS5++n7d7Nift57M89P5GXl+2l8zz2sohIiIlk5JnEbEri8Wgb6u7iXsxhAFt72Hu1iN0nBzPoh1Hyc3VVg4RESlZlDyLSIlQtWIF3uzejOUj29Ogmhsvf76bR/+xhd0Zv9o7NBERkXxKnkWkRPGrU4Ulw+5jSu8AMv57nu4fbOaVL/bw37OX7B2aiEiJ9Nprr/Hee+/lf4+JiWHq1KlX1Zk+fTpWqxWr1YqXlxdhYWHFHWaZoVd9iUiJYxgGPYPq8YBfTd5bc5BZW9L5eu8xXurkS7/Wd+NgMewdoojINb29/W1STqfYtM/GHo0Z1XrUdcufeuopHn30UZ577jlyc3NZsGAB27dvv6rOsGHDGDZsGNnZ2XTs2JHo6GibxlieaOVZREqsyi5OvPZQU1Y+G4xvTXde/fdeun+wicQj/7V3aCIiJUaDBg3w9PRk586dfPPNN7Ro0QJPT89r1n3uuefo2LEjDz/8cDFHWXZo5VlESjzfWu4siGrL8t3HGPdVMj3/sYXeQfUY1bUx1So52zs8EZF8N1ohLkpDhw5l1qxZHD9+nCeffPKadWbNmsWRI0eYNm1aMUdXtmjlWURKBcMwiAyoQ9yLofw1pCH/TvqRsMnxfLL5e3Iu59o7PBERu+rRowerVq1ix44ddO7cuUB5YmIikydP5tNPP8ViUfp3JzR7IlKquDk78krXJnz9XAes9avyxvJkHnp/E9sOn7J3aCIidlOhQgXCwsLo06cPDg4OBcqnTZvG6dOnCQsLw2q1MnToUDtEWTZo24aIlEqNalRizpOt+c++4/x9xX76frSVR6x1eOXBJtSs7GLv8EREilVubi5bt25l8eLF1yz/5JNPijmisksrzyJSahmGQZdmtVkTHcLIjo1Yuec4HSfH89GGNLK1lUNEyonk5GQaNWpEeHg43t7e9g6nzNPKs4iUeq4VHHixky89A+vx5opkxq9MYVFCBm9E+tGuUTV7hyciUqSaNm3K4cOH7R1GuaGVZxEpMxpUc+PjIa2YObgll3Jy6T9jG8/M+46ffj1v79BERKSMUPIsImVOeJOafPNCB6If8GHN/hOET1nPB+sOcTHnsr1DExGRUk7Js4iUSS5ODjwb7s2a6BA6+FTj//5zgM6xG1h34KS9QxMRkVJMybOIlGn1PSryz4Etmf1kayyGwROf7OAvcxI4evqcvUMTEZFSSMmziJQLIT7VWfV8B0Z1aczmQ78Q8c56lh68xIVsbeUQEZHCU/IsIuVGBUcLT4fey9oXQ3igaU2WpWUT8c56vtl3HNM07R2eiEiRS09PZ/78+Tett337dkJDQ/H29iYwMJBu3bqxZ88em8RQqVIlm/RjL0qeRaTcqV3FlWmPB/JyKxdcnRyImpvIE7N28P0vZ+0dmohIkSpM8nzixAn69OnD+PHjOXjwIN999x2vvPIKaWlpxRRlyaZznkWk3Grq6cBfHglm9pZ03l1zkM6xG/hLBy+eCWtExQr6z6OI3Lrj48dzcX+KTft0btKYWn/72w3rzJkzh8mTJ2MYBv7+/jg4OPDQQw/Rq1cv4Mpq75kzZxg9ejT79+/HarUyePBgXnjhhQJ9TZs2jcGDB3P//ffnX2vfvn3+5x9++IFnn32W/8/encdFVe4PHP+cWQBFRBC3VFLRUpE1t3AZDBUtoyzMq14YL9limV2XyqISS0qvmKLV7Vq5Rhm5Z5mlI4i4L0iS5pJrlguIgsp+fn+A8xMdFRWcAb7v12teDs95znO+54j45Znvec6ZM2eoV68ec+bMwd3dnaNHjxIREXFd++HDhxk8eDAFBQX06dOnnK6K9cjMsxCiWtNrNQzr1gLTGAP9vBvxybpD9JyayI+//iWlHEKISiEtLY3o6GhMJhO7d+8mNjb2hn0nTZpEt27dSElJsZg4XxnP39//hmOMHTuW8PBwUlNTGTJkCCNHjgRgxIgRFttfffVVhg8fzrZt22jYsOFdnKltkKkVIYQA6td24KOBvgzq5M67y9N4KW4nXVu6ERXSlpb1nawdnhCikrjVDHFFMJlMhIaG4uZW/ERVV1fXch2/U6dOXLhwgd69exMbG8vWrVtZsWIFAGFhYbz++usAbNq0iSVLlkv0QUwAACAASURBVFzXnpyczOLFi83tb7zxRrnGd6/JzLMQQlylQzNXvh/Rhfee8CT1RCZ9pifxwY97yc4tsHZoQghhkaqqKIpSqk2n01FUVGTenpeXV+bxPD092blzp/nrLVu28P7773P+/HmL/a89tqX2G/WpjCR5FkKIa+i0GsIfboZpbCBP+zdh1vo/eCQmgeUpf0ophxDC5gQFBREfH096ejoAGRkZNGvWjB07dgCwfPly8vPzAXByciIrK+um47388svMnTuXjRs3mtsuXfr/tfE7derEwoULAYiLizPXQwcEBFhs79KlS6n2yk6SZyGEuAG3WvZMDvVm6UsBNKjtwKsLUxg4azP7/r5g7dCEEMLM09OTyMhIDAYDPj4+jB49mueee47ExEQ6duzIli1bcHR0BMDb2xudToePjw/Tpk2zOF7Dhg359ttvefPNN2nZsiUBAQEsWrSIESNGAPCf//yHOXPm4O3tzYIFC8w11jNmzLDYHhsbyyeffEKHDh1uOHtdmUjNsxBC3IKfuwvLXu7Ct9uO85/V+3hsxgbCOt/PqF4P4FxDb+3whBACo9GI0Wgs1bZ582bz+w8//BAAvV7P2rVrbzle586dSUxMtLjt/vvvx2QyXdferFkzi+3Nmzdn06ZN5q/HjRt3y+PbMpl5FkKIMtBqFAZ3cmfdmEAGdWzKvE1HCJqawHfbj1NUJKUcQghRXUjyLIQQt8HF0Y6JT3rx/YiuNHWtyWuLUgn9bCN7/qz8H0UKIaqX1atX4+vrW+rVv39/a4dl86RsQwgh7kC7xs4sfjGAxTtPMGnVPh7/eANDOrkztveD1KlpZ+3whBDiloKDgwkODrZ2GJXOLWeeFUVpqijKOkVR9iqKkqYoyqsl7a6KovyiKMqBkj9dStoVRVFmKIpyUFGUVEVR/K8ay1jS/4CiKMYbHVMIISoDjUZhQPummMYGYny4GV9vOUaPmAS+2XqMQinlEEKIKqksZRsFwBhVVdsAnYGXFUVpC4wD1qqq2gpYW/I1QF+gVcnreeC/UJxsA+OBTkBHYPyVhFsIISoz5xp6okI8+WFkN1rVd+LNJb/S/9NkUo5nWjs0IYQQ5eyWybOqqn+pqrqz5H0WsBdoDDwBzCvpNg94suT9E8B8tdhmoI6iKI2AYOAXVVUzVFU9B/wCVP4HnAshRIk2jWrz7Qudif2HL3+fz+HJT5J5Y1Eq6dm51g5NCCFEObmtGwYVRWkG+AFbgAaqqv4FxQk2UL+kW2Pg+FW7nShpu1G7EEJUGYqi8IRvY9aOMfB89xYs3nmCHjEJzN90REo5hBCiClDK+rQsRVFqAYlAtKqqSxRFyVRVtc5V28+pquqiKMoPwIeqqm4oaV8LvA48AtirqjqxpP0d4JKqqlOvOc7zFJd70KBBg4euPJHmXsrOzqZWrVr3/LhVlVzP8iXXs/zci2t5MruIr/bm8lt6Ee5OGsLa2tHKRVuhx7QW+d4sX3I9y1dFXk9nZ2datmxZIWOXt6NHj7JlyxaeeeaZG/ZJSkpixowZfPfdd9dta9euHSaTifr161vY8+YeffRRJk6ciL+//607V7CDBw9e98CWHj167FBVtf2t9i3TahuKouiBxUCcqqpLSppPKYrSSFXVv0rKMk6XtJ8Aml61exPgZEl74DXtCdceS1XVWcAsgPbt26uBgYHXdqlwCQkJWOO4VZVcz/Il17P83KtrOegxlVV7/mbiyt+I3pLDU/6NGde3NfWdHCr82PeSfG+WL7me5asir+fevXtxcnKqkLHL29mzZ1m6dCnPPvvsDfvUrFkTnU5n8ZwURUGr1d7R+Wq1WhwdHW3iWjk4OODn53dH+94yeVYURQG+BPaqqvrRVZtWAEZgUsmfy69qH6EoykKKbw48X5JgrwY+uOomwd7Am3cUtRBCVCKKovCoVyMCH6zHJ+sO8vn6w/ycdop/92yFMaAZeq0suS9EVZEUv5+zx7PLdUy3prXo9swDN+0zf/58YmJiUBQFb29vtFot/fr1IzQ0FIBatWqRnZ3NuHHj2Lt3L76+vhiNRkaNGnXTcdPT0xk0aBBnzpyhY8eOXF2x8NVXXzFjxgzy8vLo1KkTn376KVqtluHDh7Nt2zYuX75MaGgoEyZMuPuLYEPK8hO7CxAGPKIoSkrJ61GKk+ZeiqIcAHqVfA3wI/AHcBD4HHgJQFXVDOB9YFvJ672SNiGEqBZq2ul4Lbg1q0d1p30zFyb+sJfHZiSx6VC6tUMTQlRiaWlpREdHYzKZ2L17N7GxsTfsO2nSJLp160ZKSsotE2eACRMm0LVrV3bt2kVISAjHjh0Dimfbv/32W5KTk0lJSUGr1RIXFwdAdHQ027dvJzU1lcTERFJTU8vnRG3ELWeeS2qXlRtsDrLQXwVevsFYs4HZtxOgEEJUNc3dHJkztAO//HaK91b+xqDPN/O4z3289WhrGjnXsHZ4Qoi7cKsZ4opgMpkIDQ3Fzc0NAFdX13Ibe/369SxZUlyx+9hjj+HiUlxAsHbtWnbs2EGHDh0AuHz5srkOOj4+nlmzZlFQUMBff/3Fb7/9hre3d7nFZG3yhEEhhLACRVHo7dmQ7g/U478Jh/hv4iHW7j3FK4+04tmuzbHTSSmHEKJsVFWluMr2/+l0OoqKiszb8/Ly7nj8a8e+MqbRaOTDDz8s1X748GFiYmLYtm0bLi4uDB06lJycnDs+ti2Sn85CCGFFDnoto3o9wJpRBgI83Jj80z76TF/P+v1nrB2aEKKSCAoKIj4+nvT04hKwjIwMmjVrxo4dOwBYvnw5+fn5ADg5OZGVlVXmsbt3724ux1i1ahXnzp0zH3PRokWcPn3afMyjR49y4cIFHB0dcXZ25tSpU6xatarcztNWSPIshBA2wL1uTb4wtmfO0A4UqSrhs7fy4oIdnDh3ydqhCSFsnKenJ5GRkRgMBnx8fBg9ejTPPfcciYmJdOzYkS1btuDo6AiAt7c3Op0OHx8fpk2bdsuxx48fz/r16/H39+fnn3/G3d0dgLZt2zJx4kR69+6Nt7c3vXr14q+//sLHxwc/Pz88PT2JiIigS5cuFXru1lDmdZ6toX379ur27dvv+XFleaDyJdezfMn1LD+2ei1zCwr5IukwM00HAHg5sCXPdW+Bg96214e21etZWcn1LF8VvVRdmzZtKmRsW5SVlWUTy83dDUt/Z4qilGmdZ5l5FkIIG2Ov0/Jyj5asHRPII63rM/WX/QRPX49p3ylrhyaEENWeJM9CCGGjGtepwadDHuKrZzuh0yhEzN3Os3O3cTT9orVDE0JUAatXr8bX17fUq3///tYOy+bJahtCCGHjurZyY9Wr3Zm78TCxaw7Qa9p6XuzeguGBLalhZ9ulHEII2xUcHExwcLC1w6h0ZOZZCCEqATudhue7e7B2TCB92zVkhukgPT9K5Kc9f2PL964IIURVI8mzEEJUIg2dHYj9hx8Ln+9MLXsdL361g/DZWzl0pnwfByyEEMIySZ6FEKIS6tyiLj+M7Mr4x9uSciyTPtPXM2nVPi7mFlg7NCGEqNIkeRZCiEpKp9Xwry7NMY0N5AnfxnyWeIigqYl8v/uklHIIISw6cuQIX3/99U37JCQk4OzsjJ+fH23atGHChAkVEsuKFSuYNGlShYxdkSR5FkKISq6ekz0xA3xYPPxh6tay45VvdjH48y3sP1X2p4gJIaqHsiTPAN26dWPXrl1s376dr776yvy0wisKCu7+U66QkBDGjRt31+Pca5I8CyFEFfHQ/a6sGNGViU+247e/LtA3Non3V/5GVk6+tUMTQlSw+fPn4+3tjY+PD2FhYQwdOpRFixaZt9eqVQuAcePGkZSUhK+vb5meMOjo6MhDDz3EoUOHmDt3LgMGDOCZZ56hd+/eAEyZMoUOHTrg7e3N+PHjgeIEvXXr1gwbNox27doxZMgQ1qxZQ5cuXWjVqhVbt24FYO7cuYwYMQLghvEmJCRgMBh45plneOCBBxg3bhxxcXF07NgRLy8vDh06VA5X7/bIUnVCCFGFaDUK/+x8P496NWLK6n3MTj7M8pSTvPVoa/r7NUZRFGuHKESVtm7uLE4f/aNcx6x/fwt6DH3+htvT0tKIjo4mOTkZNzc3MjIyGD16tMW+kyZNIiYmhpUrV5bp2Onp6WzevJl33nmHbdu2sWnTJpKTk7n//vv5+eefOXDgAFu3bkVVVUJCQli/fj3u7u4cPHiQ7777jlmzZtGhQwe+/vprNmzYwIoVK/jggw9YtmxZmc9/9+7d7N27F1dXV1q0aMGwYcPYunUrsbGxzJw5k+nTp5d5rPIgM89CCFEFuTra8eFT3ix7qQuNXWowOn43z/xvE7+dvGDt0IQQ5cxkMhEaGoqbmxsArq6udz1mUlISfn5+9O7dm3HjxuHp6QlAr169zOP//PPP/Pzzz/j5+eHv78++ffs4cOAAAM2bN8fLywuNRoOnpydBQUEoioKXlxdHjhy5rVg6dOhAo0aNsLe3x8PDwzzrfSdjlQeZeRZCiCrMp2kdlg4P4Lsdx5n80+/0m5lEWOf7Gd3rQZxr6q0dnhBVzs1miCuKqqrXfaqk0+koKioyb8/Ly7utMbt162ZxdtrR0bHUcd98801eeOGFUn2OHDmCvb29+WuNRmP+WqPRWKyXvlm8tztWRZOZZyGEqOI0GoWBHdwxjTHwz873s2DzUR6ZmkD8tuMUFcmqHEJUdkFBQcTHx5Oeng5ARkYGzZo1M9/kt3z5cvLzi+99cHJyIiurfG4mDg4OZvbs2WRnF68z/+eff3L69Ok7GutG8doiSZ6FEKKaqFPTjveeaMf3r3SluZsjry9Opf9/N5J6ItPaoQkh7oKnpyeRkZEYDAZ8fHwYPXo0zz33HImJiXTs2JEtW7aYZ4y9vb3R6XT4+PiU6YbBm+nduzeDBw/m4YcfxsvLi9DQ0DtOzG8Ury1SbHkt0Pbt26vbt2+/58dNSEggMDDwnh+3qpLrWb7kepaf6nwtVVVl6a4/+eDHfaRfzOUfHdx5LfhBXB3t7njM6nw9K4Jcz/JVkddz7969tGnTpkLGtkVZWVk4OTlZO4y7YunvTFGUHaqqtr/VvjLzLIQQ1ZCiKDzl3wTTWAMRXZoTv/04j0xN4KvNRymUUg4hhLghSZ6FEKIaq+2g551+bVn1ajdaN3Ti7WV7eOKTDew4es7aoQkhKtjq1avx9fUt9erfv7+1w7J5stqGEEIIHmjgxDfPdWZl6l9E/7CXp/+7kQEPNeGNvq1xq2V/6wGEEJVOcHAwwcHB1g6j0pGZZyGEEEBxKcfjPvexdoyBFw0eLEv5kx4xCcxJPkxBYZG1wxNCCJsgybMQQohSHO11jOvbmp/+3R3fpnWY8P1v9Ju5gS1/pFs7NCGEsDpJnoUQQljkUa8W8yM68tk/HyIrp4CBszbz74W7OHUhx9qhCSGE1UjyLIQQ4oYURaFPu4asGW1g5CMt+XHP3zwSk8Cs9YfIl1IOIUQ1JMmzEEKIW6php2V07wf5ZVR3Oreoywc/7qNvbBLJB89aOzQhxG06cuQIX3/99Q23X7x4kbp163L+/PlS7U8++STx8fHlHs+BAwfo168fHh4ePPTQQ/To0YP169eXy9jNmjXj7Nny/TklybMQQogyu7+uI18O7cCXxvbkFRQx5IstvBy3k5OZl60dmhCijG6VPDs6OtK7d2+WLVtmbjt//jwbNmygX79+ZTpGQUFBmfrl5OTw2GOP8fzzz3Po0CF27NjBzJkz+eOPP8q0vzVI8iyEEOK2BbVpwM+jujOm1wOs3XeKoKmJfH8oj9yCQmuHJkS1NH/+fLy9vfHx8SEsLAyAoUOHsmjRInOfWrVqATBu3DiSkpLw9fW94SO6Bw0axMKFC81fL126lD59+lCzZk0uXrxIREQEHTp0wM/Pj+XLlwMwd+5cBgwYwOOPP07v3r0JCwszbwMYMmQIK1asKHWcuLg4Hn74YUJCQsxt7dq1Y+jQoQBkZGTw5JNP4u3tTefOnUlNTb1pe3p6Or1798bPz48XXniBiniStqzzLIQQ4o446LW8EtSK/v6NmbhyL4vT/mbHtPWMD/Gkx4P1rR2eEFaR+f0h8k5eLNcx7e5zpM7jHjfcnpaWRnR0NMnJybi5uZGRkXHT8SZNmkRMTAwrV668YZ8+ffowbNgw0tPTqVu3LgsXLuSVV14BICYmhkceeYTZs2eTmZlJx44d6dmzJwCbNm0iNTUVV1dXEhMTmTZtGk888QTnz59n48aNzJs377rY/f39bxjH+PHj8fPzY9myZZhMJsLDw0lJSblh+4QJE+jatSvvvvsuP/zwA7NmzbrptbgTMvMshBDirjRxqclnYQ8xtr09Go3Cv+Zs47n52zmeccnaoQlRLZhMJkJDQ3FzcwPA1dX1rse0s7MjJCSERYsWcfbsWVJSUujdu7f5eJMmTcLX15fAwEBycnI4duwYAL169TIf32AwcPDgQU6fPs0333zD008/jU5383nb/v37065dO5566ikANmzYYJ5Jf+SRR0hPTzeXkFhqX79+Pf/85z8BeOyxx3Bxcbnra3EtmXkWQghRLtq56Xj+ye58ueEwM00H6PlRIi8aPBge6IGDXmvt8IS4J242Q1xRVFVFUZTr2nU6HUVFReY+eXl5tzXuoEGDmDhxIqqq8sQTT6DX681jLV68mAcffLBU/y1btuDo6FiqLSwsjLi4OBYuXMjs2bOvO4anp2epmwOXLl3K9u3bGTt2rPlY11IU5YbtV/9ZUWTmWQghRLmx02kYHujB2jEGerVtQOza4iT657S/K6T2UAgBQUFBxMfHk55e/CCjK2UbzZo1Y8eOHQAsX76c/Px8AJycnMjKyrrluD169ODAgQN88sknDBo0qNTxZs6caf43vWvXrhuOMXToUKZPnw4UJ8rXGjx4MMnJyaVqoS9d+v9Prbp3705cXBwACQkJuLm5Ubt27TK1r1q1inPnzt3yPG+XJM9CCCHKXSPnGnw82J+vn+tEDb2W5xfs4F9zt3H4bPnWggohipPSyMhIDAYDPj4+jB49GoDnnnuOxMREOnbsWGpW2NvbG51Oh4+Pzw1vGATQaDQ8/fTTpKen0717d3P766+/Tn5+Pt7e3rRr14533nnnhmM0aNCANm3a8K9//cvi9ho1arBy5Uo+++wzWrRowcMPP8zEiRN5++23AYiKimL79u14e3szbtw4c830jdrHjx/P+vXr8ff35+eff8bd3f02rmTZKLY8E9C+fXt1+/bt9/y4CQkJBAYG3vPjVlVyPcuXXM/yI9eyfN3oeuYXFjFv4xGmrzlAXkERz3Vvzss9WlLTTioHb0a+P8tXRV7PvXv30qZNmwoZ2xZlZWXh5ORUpr6XLl3Cy8uLnTt34uzsXMGRlZ2lvzNFUXaoqtr+VvvKzLMQQogKpddqGNatBaaxBvp5N+KTdYcImprID6l/SSmHEFXYmjVraN26Na+88opNJc53S37tF0IIcU/Ud3Lgo4G+DOrkzrvL03j56510aVmXCSGetKxftlksIUT5Wr16NW+88UaptubNm7N06dK7Hrtnz57mVTiqEkmehRBC3FMdmrny/YgufL31GDGrf6fP9CQiujZnZFAratnLf0tC3EvBwcEEBwdbO4xKRco2hBBC3HM6rYbwh5uxbmwgT/s3Ydb6P3gkJoHlKX9KKYcQwqZJ8iyEEMJq6tayZ3KoN8te7kJDZwdeXZjCwFmb2ff3BWuHJoQQFknyLIQQwup8m9Zh6Utd+PApLw6cyuKxGRuIWpHG+cv51g5NCCFKkeRZCCGETdBqFAZ1dGfd2EAGdWzKvE1HCJqawHfbj1NUJKUcQgjbIMmzEEIIm1Knph0Tn/Ti+xFdcXetyWuLUgn9bCN7/jxv7dCEqPSioqKIiYkpl3EaN26Mr6+v+ZWZmVkOEdo+SZ6FEELYpHaNnVn0YgAxA3w4lnGJxz/eQOTSX8m8lGft0ISoNgoKCm64bdSoUaSkpJhfderUuYeRWY8kz0IIIWyWRqMQ+lATTGMDGRrQjIXbjtMjJoGvtxyjUEo5hDCbP38+3t7e+Pj4EBYWxtGjRwkKCsLb25ugoCCL6y2npKTQuXNnvL296d+/P+fOnQMgMDCQt956C4PBQGxs7L0+FZsnC2oKIYSwebUd9Ix/3JOBHZry7vI03lr6Kwu3HWNCiCd+7i7WDk8Is1WrVvH333+X65gNGzakb9++N9yelpZGdHQ0ycnJuLm5kZGRgdFoJDw8HKPRyOzZsxk5ciTLli0rtV94eDgzZ87EYDDw7rvvMmHCBKZPnw5AZmYmiYmJN41r2rRpfPXVVwC4uLiwbt26uzzTykFmnoUQQlQarRvW5tvnOxP7D19OXcih/6cbeX3RbtKzc60dmhBWYzKZCA0Nxc3NDQBXV1c2bdrE4MGDAQgLC2PDhg2l9jl//jyZmZkYDAYAjEYj69evN28fOHDgLY97ddlGdUmcQWaehRBCVDKKovCEb2OC2jRg5toDfLnhMD/t+ZsxvR9kSCd3dFqZFxLWc7MZ4oqiqiqKoty0z622X8vR0fFuQqrS5CeMEEKISqmWvY43H23DT//ujneTOoxfkcbjHyez7UiGtUMT4p4KCgoiPj6e9PR0ADIyMggICGDhwoUAxMXF0bVr11L7ODs74+LiQlJSEgALFiwwz0KLm5OZZyGEEJVay/q1WPBsR37a8zfvr/yNAZ9tor9fY97s25r6tR2sHZ4QFc7T05PIyEgMBgNarRY/Pz9mzJhBREQEU6ZMoV69esyZM+e6/ebNm8eLL77IpUuXaNGihcU+N3N1zTPAsmXLaNas2d2ejs2T5PkaqqqyceNGdDrddb+lCSGEsE2KotDXqxGGB+vx6bpDzFr/B7/8dop/92yFMaAZeinlEFWc0WjEaDSWajOZTNf1i4qKMr/39fVl8+bN1/VJSEi45fGioqJKjVWdyE+TayiKQn5+Pjk5OdYORQghxG2qaadjbPCD/DyqOx2auTDxh708GpvExkNnrR2aEKKKkOTZAkVRKCwstHYYQggh7lAzN0dmD+3AF+HtySkoZPDnW3j56538df6ytUMTolKJjo4u9RRBX19fpkyZYu2wrErKNizQaDSSPAshRCWnKAo92zagays3/pf4B58mHMS09zSvBLXk2a7NsddprR2iEDYvMjKSyMjIUm1ZWVlWisY2yMyzBTLzLIQQVYeDXsurPVuxZrSBbq3c+M9Pv9N3ehKJ+89YOzQhRCUkybMFMvMshBBVT1PXmswKb8/cf3VABYyzt/L8/O0cz7hk7dCEEJWIJM8WKIpCQUGBtcMQQghRAQIfrM9P/+7Ga8EPknTgLD0/SmTG2gPk5MukiRDi1iR5tkCj0VBUVGTtMIQQQlQQe52Wl3u0ZO0YAz3bNuCjX/bTe9p61u49Ze3QhBA2TpJnC6RsQwghqof76tTgk8H+xA3rhJ1Ow7PzthMxdxtH0y9aOzQhKkRUVBQxMTHlMk7jxo3NK3CMGzeuHKKrHGS1jWuoqopDtobcs/KDUwghqosuLd1Y9Wo35iYfYfqa/fT6aD0vGFrwUmBLatjJqhyi+iooKECns5wujho1irFjx97jiKxPZp6voSgK2iKFwnypeRZCiOpEr9XwXPcWrBsbyGPejZhpOkjPjxL5ac9fqKpq7fCEuKn58+fj7e2Nj48PYWFhHD16lKCgILy9vQkKCuLYsWPX7ZOSkkLnzp3x9vamf//+nDt3DoDAwEDeeustDAYDsbGx9/pUbJ7MPFugQUNhkZRtCCFEdVS/tgPTBvoyqKM77y7fw4tf7aRbKzeiQjzxqFfL2uEJG7d///tkZe8t1zGdarXhgQfeueH2tLQ0oqOjSU5Oxs3NjYyMDIxGI+Hh4RiNRmbPns3IkSNZtmxZqf3Cw8OZOXMmBoOBd999lwkTJjB9+nQAMjMzSUxMvGlc06ZN46uvvgJg8uTJBAcH3+WZVg4y82yBRlEolBsGhRCiWuvY3JWVr3Ql6vG2pBzPpM/09Xy4ai/ZufLJpLAtJpOJ0NBQ3NzcAHB1dWXTpk0MHjwYgLCwMDZs2FBqn/Pnz5OZmYnBYADAaDSyfv168/aBAwfe8rijRo0iJSWFlJSUapM4g8w8W1Q88yw/HIUQorrTaTUM7dKcfj73MXnVPv6X+AfLdv1J5GNtedy7EYqiWDtEYWNuNkNcUVRVveX34u1+rzo6Ot5NSFWazDxbIDPPQgghruZWy54pA3xY8lIA9ZzsGfnNLgZ9vpnf/67ejykWtiEoKIj4+HjS09MByMjIICAggIULFwIQFxdH165dS+3j7OyMi4sLSUlJACxYsMA8Cy1uTmaeLdAoGopUSZ6FEEKU5u/uwvKXu7Jw2zGmrP6dR2ckMTSgGa/2bEVtB721wxPVlKenJ5GRkRgMBrRaLX5+fsyYMYOIiAimTJlCvXr1mDNnznX7zZs3jxdffJFLly7RokULi33E9SR5tkBuGBRCCHEjWo3CkE7382i7Rkz5+XdmJx9mecpJ3uzbmqf8G0sph7AKo9GI0Wgs1WYyma7rFxUVZX7v6+vL5s2br+uTkJBwy+NdPU51I2UbFmgUhUKZeRZCCHETLo52fNDfi+Uvd6GJSw3GfLebAZ9tIu3keWuHJoSoQJI8WyBlG0IIIcrKu0kdlgwP4D+h3hw+e5HHZ27g3eV7OH8p39qhCXHXoqOjzU8RvPKaMmWKtcOyKinbuIaqqhQVKhQiybMQQoiy0WgUnmnflOC2DZm2Zj/zNx1hZepfvB78IM+0b4pGI6UconKKjIwkMjKyVFtWVvW+UVZmnq+hKApqrkKRJM9CCCFuk3NNPVEhnqx8pRse9RwZt+RX+n+azO7jmdYOTQhRTiR5tkhDEao8jlUIIcQdaXtfbeJfeJjpA305eT6HJz9N5s0lqWRczLN2aMn8FAAAIABJREFUaEKIuyTJswUKxR+vFRbKihtCCCHujKIoPOnXGNMYA892aU789hP0iElgweajFBbJ5IwQlZUkz9dQVZXLOh35Gq0kz0IIIe6ak4Oet/u1ZdWr3WjbqDbvLNvD4zM3sONohrVDE0LcAUmeLXj7EU9SmraS5FkIIUS5eaCBE18/14mPB/uRcTGPp/+7iTHxuzmTlWvt0EQ1EhUVRUxMTLmM9dVXX+Ht7Y2npyc+Pj4MGzaMzMyqX98vyfM1FEVBX1hEgVZmnoUQQpQvRVHo530fa8cYGB7owYrdf/JITAKzNxymoFBuVBe2p6CgwGL7Tz/9xLRp01i1ahVpaWns3LmTgIAATp06dY8jvPdkqToLdEUqhYpGkmchhBAVwtFexxt9WjPgoSZEff8b7638jW+3HWfCE550blHX2uGJu/DOgRPsyb5crmO2q1WD91s1uWmf+fPnExMTg6IoeHt7M3HiRCIiIjhz5oz58dzu7u6l9klJSTE/ntvDw4PZs2fj4uJCYGAgAQEBJCcnExISwpgxY647XnR0NDExMTRu3BgArVZLRERE+Z20DZOZZwv0RTLzLIQQouK1qFeLef/qwP/CHiI7t4B/zNrMyG928ff5HGuHJiqRtLQ0oqOjMZlM7N69m9jYWEaMGEF4eDipqakMGTKEkSNHXrdfeHg4kydPJjU1FS8vLyZMmGDelpmZSWJiosXE+cox/f39K+ycbJnMPFugL1Qp1GgpzLf8UYUQQghRXhRFIdizId1b1eO/iYf4LPEQa/ee4rHmGgK6FmGnk3muyuRWM8QVwWQyERoaipubGwCurq5s2rSJJUuWABAWFsbrr79eap/z58+TmZmJwWAAwGg0MmDAAPP2gQMHlvn4v/76K2FhYWRlZfHBBx/c1r6VkfyLtEBfpFKo0VCQJ8mzEEKIe6OGnZbRvR5gzSgDD3vUJf73fPrGrmfDgbPWDk3YOFVVUZSbP8XyVtuv5ejoeNPtnp6e7Ny5EwAvLy9SUlLo27cvly+Xb8mKLZLk2QJ9kUqBRktBbr61QxFCCFHNuNetyRfGDvzb356CIpV/frmF4V/t4M/Mqp+UiDsTFBREfHw86enpAGRkZBAQEMDChQsBiIuLo2vXrqX2cXZ2xsXFhaSkJAAWLFhgnoUuizfffJOxY8dy4sQJc1t1SJxByjYs0hdBrkZL4Q3uMBVCCCEqmm99HS/278YXSX/w8bqDrPv9NCN6tOS57i2w12mtHZ6wIZ6enkRGRmIwGNBqtfj5+TFjxgwiIiKYMmWK+YbBa82bN898w2CLFi0s9rmRRx99lDNnztC3b18KCwupU6cO7dq1Izg4uDxPzSZJ8myBvkjlolbKNoQQQliXg17LiEda8aRfY6J/2EvMz/tZtOME4x/3pEfr+tYOT9gQo9GI0Wgs1WYyma7rFxUVZX7v6+vL5s2br+uTkJBwx8esDqRsw4IrZRtyw6AQQghb0MSlJv/950PMj+iIRqPwr7nbGDZvG8fSL1k7NCGqHUmeLdAXqRRqtTLzLIQQwqZ0f6AeP73anXF9W7PxUDo9pyXy0S/7ycmXpVVFxYiOjsbX17fUa8qUKdYOy6qkbMMCvUrxzHOB/DASQghhW+x0Gl40ePCkb2M++HEvM9YeYMnOE7zTry292za47VUVhLiZyMhIIiMjS7VlZWVZKRrbIDPPFuhVKNRopGxDCCGEzWro7MCMQX5881xnatppeWHBDobO2cYfZ7KtHZoQVZokzxbYqVCo0VIgybMQQggb97BHXX4Y2Y13+rVl59FzBE9fz+Sf9nFJSg+FqBCSPF9DVVUcah6iQKORpeqEEEJUCnqthme7NmftWAMhPo35b8IhgqYmsjL1JKqqWjs8IaoUSZ6voSgKNZz2UqTRkifJsxBCiEqkvpMDU5/xYdGLD+NS044RX+9iyBdbOHCqeteoClGebpk8K4oyW1GU04qi7LmqzVVRlF8URTlQ8qdLSbuiKMoMRVEOKoqSqiiK/1X7GEv6H1AUxaYXBbRTiwC4LHcvCyGEqITaN3Pl+1e68v4Tnuz58zx9Y5OYuPI3snLkybnVXVRUFDExMRUyTrNmzTh7tuo/Tr4sM89zgT7XtI0D1qqq2gpYW/I1QF+gVcnreeC/UJxsA+OBTkBHYPyVhNsW6UqS55xCSZ6FEEJUTlqNQtjDzVg3NpAB7ZvwZfJhHpmayNJdJ6SUQ5RZgXwKf51bLlWnqup6RVGaXdP8BBBY8n4ekAC8UdI+Xy3+V7lZUZQ6iqI0Kun7i6qqGQCKovxCcUL+zV2fQQXQl/xQuVxYZOVIhBBCiLtTt5Y9Hz7lzcAO7oxfvodR3+7m6y3HmBDSjrb31bZ2eFXOhO/T+O3khXIds+19tRn/uOdN+8yfP5+YmBgURcHb25uJEycSERHBmTNnzI/ndnd3L7VPSkqK+fHcHh4ezJ49GxcXFwIDAwkICCA5OZmQkBDGjBlTrudT2d1pzXMDVVX/Aij588ozQhsDx6/qd6Kk7UbtNslctiHJsxBCiCrCt2kdlr7UhUlPeXHwdDb9ZiYRtSKN85ellKOyS0tLIzo6GpPJxO7du4mNjWXEiBGEh4eTmprKkCFDGDly5HX7hYeHM3nyZFJTU/Hy8mLChAnmbZmZmSQmJt40cZ42bVqph6ecPHmyQs7P1pT3Q1Isrcyu3qT9+gEU5XmKSz5o0KBBmZ+vXp60RcVJc/qFC1Y5flWTnZ0t17EcyfUsP3Ity5dcz/JVUdezIfB+Zz1LDqrM23iExduP8MwDdnRprENThR+wUpHfn87OzuYHh4wOdL9F7ztzsweT/Pjjj4SEhGBvb09WVhZ6vZ6NGzcyb948srKyePLJJ3nttdfIysoiNzcXvV7PiRMnOHfuHP7+/mRlZfH0009jNBrJysqisLCQxx9//IbHLCwsJDc3l5deeqlUUt6uXTuys7Oxt7cv9/Mvbzk5OXf8/XCnyfMpRVEaqar6V0lZxumS9hNA06v6NQFOlrQHXtOeYGlgVVVnAbMA2rdvrwYGBlrqVqG2rFoOgNbREWscv6pJSEiQ61iO5HqWH7mW5UuuZ/mq6OvZrzfs+fM841ek8eWec+y8UJP3Qtrh1cS5wo5pTRV5Pffu3YuTk1OFjF0W9vb22Nvbl4pBURScnJzQ6/Xk5+ej0WhwcnIq1fdKH4BatWqZ+2i1WurVq3fDc8rKyrrhMWvVqmXVa1FWDg4O+Pn53dG+d1q2sQK4smKGEVh+VXt4yaobnYHzJWUdq4HeiqK4lNwo2LukzSZdqXnOLZIbKoQQQlRd7Ro7s+jFh5k6wIfjGZcJ+WQDby39lXMX86wdmrgNQUFBxMfHk56eDkBGRgYBAQEsXLgQgLi4OLp27VpqH2dnZ1xcXEhKSgJgwYIFGAyGext4JXXLmWdFUb6heNbYTVGUExSvmjEJiFcU5VngGDCgpPuPwKPAQeAS8C8AVVUzFEV5H9hW0u+9KzcP2iJ9SZVJrtyNLIQQoopTFIWnH2pCL88GTP/lAPM2HeHHX//iteAH+UcHd7SaqlvKUVV4enoSGRmJwWBAq9Xi5+fHjBkziIiIYMqUKeYbBq81b9488w2DLVq0sNhHXK8sq20MusGmIAt9VeDlG4wzG5h9W9FZiV4t/kGRY+U4hBBCiHultoOedx9vy8AOTXl3+R4il+5h4dbjTHjCE393m11dVpQwGo0YjaUfo2Eyma7rFxUVZX7v6+vL5s2br+tTllrgq8e54siRI7fcryqQJwxacCV5lg+thBBCVDcPNnRi4fOdmTHIj9NZOTz16UZe+243Z7NzrR2aEDahvFfbqBKulG3kySdVQgghqiFFUQjxuY+g1vWZYTrA7A2H+Sntb8b0eoB/dr4fnVbm3qqL6Ohovvvuu1JtISEhvPfee1aKyPokebbArmRCXmaehRBCVGeO9jre7NuGAQ81ZcL3aUR9/xsLtx3nvSfa0bG5q7XDE/dAZGQkkZGRpdputmxedSC/OlqgV0uSZ43cMCiEEEK0rF+L+REd+eyf/mTlFPDM/zbx74W7OH1B7g4S1Y8kzxbYKVoA8iV5FkIIIYDiUo4+7RqxZrSBVx5pyY+//k2PmAQ+X/8H+fJEXlGNSPJsgR5JnoUQQghLathpGdP7QX4e1Z1OLeoS/eNe+sYmkXzwrLVDE+KekOTZAkWxQ6/mUqCV5FkIIYSwpJmbI7OHduCL8PbkFhQy5IstvBy3k5OZl60dmhAVSpJnCxTssSOPfFkYXgghhLipnm0b8MsoA6N7PcCavacImprIJ+sOkltQaO3QhAVRUVHExMTYzDiVkSTPlih26MmnQGvtQIQQQgjb56DXMjKoFWtGG+j+gBtTVv9On+lJJPx+2tqhibtUUFBg7RBsjixVZ4Gi0WNHHgUa+d1CCCGEKKumrjX5X1h7EvefIWpFGkPnbKN32wa8068tTV1rWju8e2PVOPj71/Ids6EX9J100y7z588nJiYGRVHw9vZm4sSJREREcObMGfPjud3d3Uvtk5KSYn48t4eHB7Nnz8bFxYXAwEACAgJITk4mJCSEMWPGlO/5VHKSHVqgaOyKk2etlG0IIYQQt8vwQD1++nc33ujTmg0Hz9Lzo0Ri1xwgJ19KOSpCWloa0dHRmEwmdu/eTWxsLCNGjCA8PJzU1FSGDBnCyJEjr9svPDycyZMnk5qaipeXFxMmTDBvy8zMJDExURJnC2Tm2QJFsUNPHgUauTxCCCHEnbDXaRke6MGTfvcR/cNepq3Zz6Kdx3m3nyc929RHUaroBNUtZogrgslkIjQ0FDc3NwBcXV3ZtGkTS5YsASAsLIzXX3+91D7nz58nMzMTg8EAgNFoZMCAAebtAwcOvEfRVz4y82zJlZlnjRQ9CyGEEHejkXMNPh7sz9fDOuGg0/Lc/O1EzN3GkbMXrR1alaGq6i1/GbndX1YcHR3vJqQqTZJnC5SSGwbzJXkWQgghykVASzd+fLUbbz/Whm1HztF72npiVv/OpTy5Ie1uBQUFER8fT3p6OgAZGRkEBASwcOFCAOLi4ujatWupfZydnXFxcSEpKQmABQsWmGehxc1JXcI11KIiHFJ+w863AQWKpky/zQkhhBDi1vRaDcO6tSDE5z4+XLWPj9cdZMnOE7zTry192jWU/2/vkKenJ5GRkRgMBrRaLX5+fsyYMYOIiAimTJlivmHwWvPmzTPfMNiiRQuLfcT1JHm+lqLgPCcOfewrFGp0FBUVodXKDLQQQghRXurXdmDaQF8GdXTn3eV7GB63k64t3YgKaUvL+k7WDq9SMhqNGI3GUm0mk+m6flFRUeb3vr6+bN68+bo+CQkJtzze1eNUN1K2cQ1FUVD1DujJI1+jpVA+ThJCCCEqRMfmrqx8pSsTQjzZfSKTPtOT+PDHvWTnyv+9wnZJ8myJfQ30RQUUKHoKcvOtHY0QQghRZem0GowBzVg3NpCn/Bvzv/V/EDQ1geUpf6KqqrXDq/aio6Px9fUt9ZoyZYq1w7IqKduwQK3hgF4tpECjoyBPkmchhBCiornVsuc/oT4lpRxpvLowhbgtx3jvCU9aN6xt7fCqrcjISCIjI0u1ZWVlWSka2yAzzxYU2TugLyokX9FRKAu6CyGEEPeMn7sLy17uwgf9vdh/KovHZmxgwvdpnL8sk1nCNkjybIFaozh5LlR05OXkWTscIYQQolrRahQGd3Jn3ZhA/tGhKXM3HiFoagKLdpygqEhKOYR1SfJ8DVVVSdEXoSsqvllB1p8UQgghrMPF0Y7o/l6seLkrTVxqMva73Qz43yb2/Hne2qGJakyS52soikIGBf+fPOfLx0RCCCGENXk1cWbJ8AD+E+rNkbMXCfl4A28v+5XMS/LpsLj3JHm2QEFBX1Bc6ywzz0IIIYT1aTQKz7RvimlsIOEPN+PrLcfoEZPAN1uPSSnHbYiKiiImJsZmxqmMJHm2QKMo6AqLk+fLBXLDoBBCCGErnGvoiQrx5IeR3WhV34k3l/xK/0+TSTmeae3QqqSCAplEvJYsVWeBotGgKyz+Zrksq20IIYQQNqdNo9p8+0JnlqecJPrHvfT/NJmB7ZvyWvCD1K1lb7W4Jm+dzL6MfeU6ZmvX1rzR8Y2b9pk/fz4xMTEoioK3tzcTJ04kIiKCM2fOmB/P7e7uXmqflJQU8+O5PTw8mD17Ni4uLgQGBhIQEEBycjIhISGMGTOmXM+nspOZZws0Gg26Apl5FkIIIWyZoig86dcY0xgDw7o2Z9GOE/SISWD+piMUVqNSjrS0NKKjozGZTOzevZvY2FhGjBhBeHg4qampDBkyhJEjR163X3h4OJMnTyY1NRUvLy8mTJhg3paZmUliYqIkzhbIzLMFikZ7VfIsH1cIIYQQtszJQU/kY215pn1Txq9I493laSzcepz3nvCkfTPXexrLrWaIK4LJZCI0NBQ3NzcAXF1d2bRpE0uWLAEgLCyM119/vdQ+58+fJzMzE4PBAIDRaGTAgAHm7QMHDrxH0Vc+MvNsgUarRZdfnDTnFBZZORohhBBClEWrBk7EDevEJ4P9OXcpj9DPNjE6PoXTWTnWDq1CqaqKoig37XOr7ddydHS8m5CqNEmeLVC0OrQlj+W+JDPPQgghRKWhKAqPeTdi7RgDLwV68P3ukwTFJLL6SD75VXRCLCgoiPj4eNLT0wHIyMggICCAhQsXAhAXF0fXrl1L7ePs7IyLiwtJSUkALFiwwDwLLW5OyjYsUHQ6lLzitSMv51+2cjRCCCGEuF017XS83qc1oQ81YcL3v/HNvjPsnLGBqBBPHvaoa+3wypWnpyeRkZEYDAa0Wi1+fn7MmDGDiIgIpkyZYr5h8Frz5s0z3zDYokULi31upKCgAHt7692YaU2SPFug0enQ5WYDcOFy1f6oRwghhKjKWtSrxdx/dWBa/FqWHClg0OebedznPiIfbUNDZwdrh1dujEYjRqOxVJvJZLquX1RUlPm9r68vmzdvvq5PQkLCLY+XlpZGQEDAbcdZFUjZhgWKXo/jxSwAzuTloRZUzY95hBBCiOpAURT8G+hYM9rAq0GtWJ32N49MTeCzxEPkyf/xt61z585oNBp69+5t7VCsQpJnCxS9Hn1eAS5qOvudHMg9fN7aIQkhhBDiLjnotYzq9QBrRhkI8HBj0qp99IldT9KBM9YOzWZFR0fj6+tb6vX000+zePFidLrqWcBQPc/6FhSdnqJ86Ewyq+v04/i+07Rq5WLtsIQQQghRDtzr1uQLY3vW7TtN1PdphH25lT6eDXm7XxuauNS0dng2JTIyksjIyFJtWVlZVorGNsjMswWKVktRoUI3EijSaFiYLb+RCiGEEFVNj9b1Wf3v7rwW/CAJ+0/T86NEZq49QI48XVjchCTPFmi0WooKFNw5inPeBTbbyXJ1QgghRFXkoNfyco+WrB0TyCOt6zP1l/0ET1+Pad8pa4cmbJQkzxYoWi2FBQoK4FpwkXStXCYhhBCiKmtcpwafDnmIBc92RKdRiJi7nWfnbuNY+iVrhyZsjGSFFmi0OooKip/E41x4mSy9lIYLIYQQ1UG3VvVY9Wp33nq0NZv/SKfntEQ++mU/l/OklEMUk+TZAkWrJT+n+NI4c5GLer2VIxJCCCHEvWKn0/B8dw/Wjgmkb7uGzFh7gJ4fJbI67W9UVbV2eGUSFRVFTEzMbe2zYsUKJk2aBMCyZcv47bff7ujYgYGBbN++HYBmzZrh5eVlXqlj48aNdzSmLZEpVQsUjZaCXA2F+fbU1F0gX6st03PjhRBCCFF1NHR2IPYffgzq6M745Wm8sGAH3R+oR9TjbWlRr5a1wytXBQUFhISEEBISAhQnz/369aNt27Z3Pfa6detwc3O763FshSTPFmi0WkAh67g/tZqdoFCjIS+vEHt7uVxCCCFEddO5RV1+GNmV+ZuOMq3khsJh3VowokdLHK/JDf7+4ANy9+4r1+Pbt2lNw7feummf+fPnExMTg6IoeHt74+HhYd72+eefM2vWLPLy8mjZsiULFiygZs2aDB06FFdXV3bt2oW/vz9eXl5s376dwYMHs2LFChITE5k4cSKLFy9mwIAB7Ny5E4CDBw8ybNgwduzYUa7nWVlI2YYFilYLQObhzjhoLgJwMVdW3BBCCCGqK51WQ0TX5pjGBhLi05j/Jhyi50eJrEw9ae3QSEtLIzo6GpPJxO7du4mNjS21/amnnmLbtm3s3r2bNm3a8OWXX5q37d+/nzVr1jB16lRzW0BAACEhIUyZMoWUlBQ8PDxwdnYmJSUFgLi4OIYOHVrm+Hr06IGvry+dOnW6uxO1ETKVasGV5PnymfuxKzwAOsjKyce1toOVIxNCCCGENdVzsmfqMz4M7tSUd5enMeLrXcx/qjHN8wtx0GtvOUNcEUwmE6GhoebSCFdX11Lb9+zZw9tvv01mZibZ2dkEBwebtw0YMABtSd5zM8OGDWPOnDl89NFHLF682FzTXBZVrWxDZp4t0GiufBMV4VBoB8CFS7nWC0gIIYQQNuWh+11ZMaIr7z/ZjvzCIg6cyuZk5mUKi4rueSy3ui9r6NChfPzxx/z666+MHz+enJwc8zZHR8cyHePpp59m1apVrFy5Ej8/P+rWrXvXcVdWkjxfQ1VVsgs1Je8LcCgsnpzPvJxnzbCEEEIIYWO0GoWwzvfTsLYDLo56zmbn8vupbM5dyrunq3IEBQURHx9Peno6ABkZGaW2Z2Vl0ahRI/Lz84mLiyvTmE5OTqUew+3g4EBwcDDDhw9nyJAh5Rd8JSTJswVf/X5lLcdC7AuLZ6GzciV5FkIIIcT1NBqFJi41aVm/FnZaDcczLvHHmYv3bG1oT09PIiMjMRgM+Pj4MHr06FLb33//fTp16kSvXr1o3bp1mcb8xz/+wZQpU/Dz8+PQoUMADBkyBEVRCAoKKvdzqEyk5vkaiqKUrLYBqIU4lNwneCFXyjaEEEIIcWM17XR41HPk3KU8/j6fy8HTWbjWsqdBbXt0moqdrzQajRiNRovbhg8fzvDhw69rnzt3bqmvhw4dar4RsEuXLtet87xhwwYiIiJuWSOdkJBgfn/kyJFbxl7ZSPJsgWJ+HPdVyXPeZavFI4QQQojKQVEUXB3tqe2g51RWLhnZuZy/lE9DZwdcauor7TMj+vfvz6FDhzCZTNYOxeokebZA0ZRcFrUQh/zib/KsAkmehRBCCFE2Oq2GxnVq4FpTz8nMHE6cu0TGRR331XGgpl3lS7+WLl1qfn+lFrp///4cPny4VL/JkyeXWs2jKqp8f3v3gEZX/HGESiEOuSXJc6GUbQghhBDi9tSw09GiniOZl/L563wOB09n4+poR8PaDui0lfvWs6sT6upEkmcLzEvVqYXos4pvFMwukhsGhRBCCHH7FEXBxdGO2jV0nLqQS3p2Hucv59OwtgOujnaVtpSjuqrcv/JUEK3uSiF8IflH0tGruVwskicMCiGEEOLOaTUa7qtTg1YNauGg1/Jn5mUOns6WpxhXMpI8W3B18lyQrcWBHC6p937RcyGEEEJUPQ56LS3cHHF3rUlBkcqhM9kcz7hEfqHkGpWBlG1YoNUWX5Zarnqy81viQA6XlXu32LkQQgghqjZFUahT0w4nBz2ns3I4m53HhZx8GtR2oK6Uctg0mXm24MrMc937apCluGNPDrLWhhBCCCHKm1aj0Mi5Bq3q16KGXsvJzMscOJ1N9l2WckRFRRETE3Nb+6xYsYJJkyYBsGzZsuvWeS6rK4/w9vHxoW3btvzvf/+7LqbvvvsOT09PNBoN27dvv6PjWIvMPFugK1n8u059O44fqokDF7ms1LJyVEIIIYSoqhz0Wpq7OXIhp4C/Mi/zx5ls6tS0o5GzA/p7sCpHQUEBISEhhISEAMXJc79+/Wjbtu1tjZOfn8/zzz/P1q1badKkCbm5uRYflNKuXTuWLFnCCy+8UB7h31OSPFug0xdflhq1tNihxZ5ccpTaVo5KCCGEELYuKX4/Z49n3/U4eYVF5hro+k2d6DmkNZqblHLMnz+fmJgYFEXB29sbDw8P87bPP/+cWbNmkZeXR8uWLVmwYAE1a9Zk6NChuLq6smvXLvz9/fHy8mL79u0MHjyYFStWkJiYyMSJE1m8eDEDBgxg586dABw8eJBhw4axY8eO6+LIysqioKCAunXrAmBvb8+DDz54Xb82bdrc1fWxJinbsEBfUrZRWJiPo4OCfVEuOYr8niGEEEKIe8NOq6GGXotWUbiYV8CBU9lk5+Rb7JuWlkZ0dDQmk4ndu3cTGxtbavtTTz3Ftm3b2L17N23atOHLL780b9u/fz9r1qxh6tSp5raAgABCQkKYMmUKKSkpeHh44OzsTEpKCgBxcXHmx3hfy9XVlZCQEO6//34GDRpEXFwcRUVV60ZIyQgt0Gs1qEBhziUcLl/AUb3MBcXB2mEJIYQQwsZ1e+aBch/zwuV8Tp6/zB9nL+JcQ08j5xrY6f5//tNkMhEaGoqbmxtQnMBebc+ePbz99ttkZmaSnZ1d6gmAAwYMQKvVcivDhg1jzpw5fPTRRyxevPimdcpffPEFv/76K2vWrCEmJoZffvnl/9i787iqyvyB459zL8sF7mVHRUFwX9k0JTVzlzSj3BK0RjK1aLRGp0YbrTRl1LSanH4zk+YeZSbJoFmWmc7kVi6o4IIi7qgsguxc7j2/Py6RyCIqguX3/Xqdl/ee59xznvN49fXl4Xu+DytXrrzNu75/ycxzJWysFEyKlpKcdGzNGbiWXOO61kDBD/Oh6O5/FSOEEEIIUVOOdta0bmCgoaOOnMISkq7kcPV6IWbVUglMVdVqq3NERETw4YcfcuTIEd566y0KCwvL2hwcHGrUh+HDh/P111+XPQz4S1pGVfz8/JgyZQrfffcdMTExNbrGb4UEz5Ww0YBJ0WLMy8JWk4urKQuA4wc2wIcPwaEFgQ1oAAAgAElEQVS18Dv7FYQQQggh7l8ajUJDRx2tG+ox6Ky4fL2Qk1dyuF5opF+/fqxbt46MjAwAMjMzy302JycHT09PjEYj0dHRNbqewWAgJyen7L1OpyMkJITIyEjGjBlT5edyc3PZvn172fv4+Hh8fHxu407vfxI8V8JGq2BCS0l+DjbaQloVnsZOzWd2939hNjSGDS/AsgFwoWKivBBCCCHEvWJjpcXHzYFm7g6Awpn0PBwa+jJt+uv06tWLgIAApk6dWu4zc+bMITg4mAEDBtC2bdsaXScsLIyFCxcSFBREcnIyAGPGjEFRFPr161fl51RV5Z133qFNmzYEBgby1ltvVZqysWHDBry8vNi9ezePP/54uVSS+53kPFfCRmuZeS4pyMHKyhF9sZHRxs9YpjzPikFreT5jK2ydBR/3hQ7DoM8McG9Z390WQgghxAPCoLOmVUMr0nOLuHq9iOCQYXw/IhwPvS0aTfkUjsjISCIjIyuc4+agNiIiouxBwB49elSo8/zjjz8ybty4anOkDQYDmzdvrrRt1qxZZa+HDh3K0KFDq7nD+5cEz5XQaRVyFC2monysda4U5TvRu+FmTjpNJirlMgO6DKdpuyfgx/dh70dwfBP0mgZdxoOdc313XwghhBAPAI2i0MCgw9nOhsvZBVy5Xsi1/GIaO9lh0FnV6iqFQ4cOJTk5mW3bttXaOX+rJG2jEjorMCkaTEUFWNnZUZTvjEaBN/QZKMCrJ86j2uih35sw+QC0Ggjb5sD7HeD7OZCbVt+3IIQQQogHhI2VhqZuDjR3d0CDwpmMPM5k5FNkNNXaNTZs2MDhw4fLKnqAJaAODAwst23ZsqXWrnm/kpnnm5SU5GBv9QEmxQ2zsQitnR3X0n1parQlLyWKNzosZ/rJS0SnZvJMYzcwNISwaLh4AHb+Hf63CHYtho4j4OFI8PSv71sSQgghxANAr7OmZUMrMnKLuXq9kKSruXjobfAw6NBqam8W+hcbNmyo9XP+FsjM802srAw4WKuYFC1qSTFW9nqMxQ6kJnUlz/oYPdO/5BFnPW+eukhKftGvH2zSCZ5eDZP2Qac/wNH/wEc9YeUQOBoHprtbo14IIYQQ4lY0ioKHwZbWjQw421lzNaeIpCs5ZOcXo5aWthN3R4LnShhsBqMqGlSzGSt7A6Ah/YInDlkBnEtbzHxfa6wVhcijZzGab/oiureCx9+FqUdhwBy4dhbWPQsfBMCOhZBzpV7uSQghhBAPDmutBm9Xe1p46NFqFM5m5pOSnkdhLaZyPKgkeK6EnZU9WsWMyayg1RvQmK0o0ii09n4DVYWsw6+zqLUX8Tn5LDpzuYqTOEOPl+GVeAj71FKN44e5lrzomAlS5k4IIYQQ95yDrRWtGuhp7GxHgdHEySu5pGYXYLp58k/UmATPldAoDug0xZSoGqwc3dCYbSi2sUbJTKNR5jNkm/bSufB7wj1dWXz2Com5BdWcTAttH4c//Acm7bdU5DjxtaXM3dK+sG855GdW/XkhhBBCiNs0a9YsFi1aBICiKLjrbWnT0ICLvTVppakcWTelcsTFxTF//nwAYmNjK5Sqq6lfViEMCAigffv2fPTRRxX69Nprr9G2bVv8/f0ZOnQoWVlZd3O7dUqC50rpsdcUYlI1aJ0aoTHZgKJw7m9/w6dDOLqsliSdmsPUxhpU4MdrObc8I2CZfR40H/58DAYttCz1vWkKvNMcPgiET8Ms1ToSYyH7wj29QyGEEEI8WKy0Grxc7WnZQI+VVuFcZj6n0/MoMJooKSkhNDSU6dOnA3cePBuNRiZOnMjGjRs5dOgQBw8epHfv3hWOGzBgAAkJCRw+fJjWrVszb968u729OiPVNiqlw6ApxKQqWLk2QmO2ASBTZ0v6otk0H/lXjpkiuZLwGu7WMziWW3iL893E1gDBE6HrBEg9BEnfwNVjlu3kt6CW5iM5ekHTYGjaDZo+DA06gEZ+3hFCCCFEeatXr2bRokUoioK/vz8tWrQoa1u6dClLliyhuLiYli1bsmbNGlp66Bn97B+wsXfkWMJhgjp1omunAA4eOMDo0aOJi4tjx44dzJ07l5iYGEaOHMmBAwcAOHXqFOPHj2f//oopqDk5OZSUlODm5gaAra0tbdq0qXDcwIEDy14//PDDrF+/vraH5J6R4LkSiqLgrOSRrVqjtbXBptgFBzs9iX360GDVahoEd6eR7bOkNvuY5naZHMuzvtMLQeNAy/YLYyFcTYTzP8P5PXB2NyTEWNrsXKF5L2je27K5+N7VfQohhBCidv2wcglXz56u1XM28GlOn4iJVbYnJiYSFRXFzp07cXd3JzMzk8WLF5e1Dxs2jAkTJgAwc+ZMli1bxuTJk7G10pJ28Qzr4zaTVWhi4xefUWg00a1bN0JDQxkyZAgjRowAwMnJifj4eAIDA4mOji5bifBmrq6uhIaG4uPjQ79+/RgyZAjh4eFoqpn8W758OaNGjbqDkakfEjzfxGxWufS/AmxNdhSqGrTWGhRVS+f2Pfjv/i2ce/JJNP+3mMYLl5NzdT9uDf7HD8WPY1JVtLWxko+1Dpp0tmwPvwiqCtnnLUH06e1w+gdILK2r6NKsNJDuBc16gb3r3V9fCCGEEL8p27ZtY8SIEWULmLi6lo8HEhISmDlzJllZWeTm5hISElLW9vTTT9PU3YBHcQlWWoXcohKS0/Iwmc3lzjF+/HhWrFjBe++9R0xMDPv27auyPx9//DFHjhxh69atLFq0iO+++67CUuC/iIqKwsrKijFjxtzh3dc9CZ5votEoZKda4ag6UWzOp7g0kd7T3YdWrVpx8MwZmvj6kjbvVbxffANvPqfQDMn5RbR20NV+hxQFnJtatoBRlmA6PckSSCf/AEfWw/4VgAKN/KDZo+D7CPh0B51T7fdHCCGEEFWqbob4XlFVtdqluCMiIoiNjSUgIICVK1eyffv2sjYHBwcA7GysaGCwRW9rRXGJmesFJWTkFlFiMmOl1TB8+HBmz55N3759CQoKKkvLqIqfnx9+fn48++yzNGvWrNLgedWqVWzatInvv/++VpcSv9ckgbYS1poiTNiioJKWVwyAuURl0KBBmMxmjg0fhikvj6JNa2lbfAmAn7Lz6qZzigIebSD4BRi9Fqadgee/gz5/BVtH+GkpfBYGC3zhX4/AV3+Gw+ss9aalOLoQQgjxu9OvXz/WrVtHRkYGAJmZ5at45eTk4OnpidFoJDo6usrzKIqCzlpL60Z63FycuJqRRdKVHDLyirC1tSUkJITIyMhqZ4lzc3PLBefx8fH4+PhUOO6bb75hwYIFxMXFYW9vf5t3XL9k5rkStkoORq0DWjWNK3mWMnQlxWZcXV3p2bMn27dvp8NfX0ed+SbNnmqNk0cOe7JyLct11zWtFXh3tWy9/gLGArjwM5zZacmZPrQWfv7Ycqy+IXh1sWzewdA4yJImIoQQQojfrA4dOjBjxgx69eqFVqslKCgIX1/fsvY5c+YQHByMj48Pfn5+5ORUXyXMSqPh+bHPMH78BD5buYSF/1pJ69YtGf70KL788kv69etX5WdVVeWdd97hhRdewM7ODgcHh0pnnSdNmkRRUREDBgwALA8N/vvf/76j+69rEjzfrCgXW3Io1OpRgCvXLT+9mUosuT89evTg0KFDbLt0iadfmUxB2s+08UhgV5YLRrOK9T1YO/62WNtZUjeaPWp5bzbBlUS48BOcL92Ob7K0aW3AM9BSycOnB/j2sFQCEUIIIcRvytixYxk7dmylbZGRkURGRlbYf3NQGxERUfYgYI8ePTh27CiqqpJdYCQ1u5CNW35gRPizoFSduGAwGNi8eXOlbbNmzSp7ferUqepv6D4mwfPNbPXku7ZAvWYJmtOup2GDQkmxpXyctbU1jz/+OJ988glHH3mEhjtO0KX9Hn4q6sbI+FMs7eiLh80dVt+4FzRa8PS3bF3GW/blpsH5vZaZ6XN7Yc+/YNdi0FhZZqRb9IHmfS1VQDTa+u2/EEIIIeqNoig429sQMXoUSSdP8e/P/sOFXDMl2iLcHGx+U7nKtUWC50pobRTU0trOGdezaWLlUjbzDNCyZUv8/PzYuXs3oYVN6K5uws09hIXXOhCyL4llHZsR5Hgf5+/oPaDdEMsGllSP8z9B8jZLNY9tcy2bztkyg928tyWgdmlmybkWQgghxAMlNtZS6avQaOJ8Ri6XsgoIf3oEVy6eQ3NDbLBgwYJy1Tx+jyR4roTGGswmy4xr5vUCfKzdKSkuX7IlJCSEkydPstdRpUN2Mx6yWUtcp7WMSzjDkwdOMr+1F6PrIwf6TljbldaP7gXMhrz00rJ4pduxOMtxzk2heR9o0dcSVEtpPCGEEOKBorPW0tBeQbWyY/GyaIwmMy72NjRy0mGtfTDqUEjwXAmtDZQYLV+ArLxitNYaSkrKB896vZ5+/frx1Vdf0TazBYVOW2ma9x1bHnqcyMSzTD1xnvicfOa0aoLtb21VQAd38Bth2VQVMk9bZqSTS2tMH1hlyXdqHPRrMO3VBaxs6rvnQgghhLjHFEXB0d4Gvc6atJxC0nKLuV5gpIGjDje9TbmZ6N8jCZ5vYiopwSPtCrmmfIqB63kmrKw1mIzmCse2b9+er776iryznXFyOEaiMpUWzVOJ9p/I/JTLfHjuKsdyC/m4oy8NbS150Kqqcj6zgD0pGRw8d43L2YXkFJbg7WpPc3cHmrrZ4+vmQDMPBxx190HutKKAWwvL1mU8mErg4v5fUzx+fA/+twhs9Jb60i36Wja3lpLiIYQQQvyOaTUKjZzscLG34VJ2IanZBVzLL6axkx163e83xPz93tkdUjQaWpZ4kmVzhux88L9iR4mDiawr+aQcTkfnYI2juw57Rxvs7e2xsbEhr1il7Q9jSOu2imQWUliUyozWb+JvsOeVY+fos/c4oxQd6Rdy2Xcmk9TsQgCc7a3xdrHH3kbL3tMZbDh4sVxfPAy2NHd3oJm7A77uDvi62ePr7oCPqwN2NvX0IJ/WCpoGW7Y+r0NBFpz5n2VWOnkbJH1jOc7RqyxX2rpYvmZCCCHE75WttRZfN3tyCku4lFXA6fRcnO0sqRw2Vr+x377XgEQ1N9FoNBjNhTjq7SALHEqgIMdIQY6Rzf88XHaclbUGg5sOrVZHhtaElVt7DP+yQnnSmYvdPiHpUjIbz72I7koR1zo48S9dCa5F+fT2ceGlZq483NyNlg305Z5SLSg2cS4znzMZeaSk53Hqai4p6Xl8d/QKGaWLtfzC00mHr5sDvu72pX86lM1c21rVYWBt5wztnrBsAJkpv6Z4HN8E8Z/QAyDZz5JT3aKvZfVDa7u666MQQggh7ilFUXC0s0Zva0VabhFpOUVcLzTSwNEWd73t7yqVQ4LnShSrRViXDs1Gu0Je9nDAxlrLo2Gtyb9ezPX0Qq5nFJCTUUjqZTsySnIxmhRse8+m8Psl2J8/iDpyNz1dr9DY6S3aeDYkjiK2axQuODnQvoUHrZwcKlzXzkZLm0YG2jSqWGs5u8DI2Yw8zmTkcyY9z7Jl5LEl8QqZNwTWGgW8XOxpVjpj3dzjlz/1eDrq0NzrOtSuzSzbQ+MsNaZT4zm9dTnN1bPw0xLY/SFobS0B9C8pHg07SIqHEEIIUYtmzZqFXq/n1VdfrfFn4uLiOHr0KNOnTyc2NpbWrVvTvn3727ru22/PpqioiNlz5nIpq5DL2YXs2rufaZOe58Tx4yxfvpz3338fRVEwm81ERUXx5JNP8sUXXzBr1iyOHTvGTz/9xEMPPXS7t1xnJHiuhJFiNGbLrxm0mMBag0ar0MDHEQCTWeXguWvsPH6VC9d1OOamEWXMZ4qVPW5dXiTr5HfYLlmHZvxZWjq8QWDblYTbteDzy5lEnU7l8QMnGejmyKvNGuFvqFlJOyc7a/y9nPH3cq7Qlp1vLJutPp2ex+m0XE6n5fHzmUzyS+tTA9hZa2nu4UALD31ZUN3CQ4+vuwN623vwVdBooUlnzvnk0Lx3byjOg7O7Lekdydvguzcsm0MD6PAUPPQ8NGhb+/0QQgghRLVKSkoIDQ0lNDQUgNjYWIYMGXLbwXN4eDiDBg1i3rx5+Lo7cL3QyIf/WU//IcPZcySJuVFRHDxwACcnJ3Jzc0lLSwOgY8eOfPnll7zwwgu1fm+1TYLnm6hGI+a8a1iXpj5oVRMlqBQXmdh8JJWtx67ww/GrXMs3YqVR6OVii5ti5o+TAmndyJUryxJxVQaScdUXt/cXkfHSRX7aO4xOnVcQ5unPEx7OLL2Qxr/OpzFwXxJdnRwI93Ql1MMZhztMt3CytybA3pkA7/KBtaqqXM0p4nRaHsmlAfXp9FwOnLvGxsOXUNVfj21gsC03U93M3RJgN3W1r73SMzYO0Kq/ZQO4fslSCi9pC+xfaZmZ9ulhmbVuFyrVO4QQQogaWr16NYsWLUJRFPz9/WnRokVZ29KlS1myZAnFxcW0bNmSNWvWYG9vT0REBK6urhw8eJBOnTrh5+fHvn37GD16NHFxcezYsYO5c+cSExPDyJEjOXDgAGBZHXD8+PHs37+/Qj/atGmDs7Mze/fuJTg4GEedNVu/+g+fxsRx7mIqNjp78sxWGMwqer0evV4PQLt27epmoGqBBM83UaytKTEVYG1jCUS1qon9F7JxNSusiD6Ak501fdp40L99Qx5t7cHVC2f55JMkXDQF2DjY4DUpkOxvUuC/UNjw7/DBG2S+cI2f9ozCw/A2fl2H8yffRozz8mDNpQw+vZTBlOPnmXHyIkM8nBjVyJVuzvpayQ1SFIWGjjoaOuro1qJ8zelCo4mzGfmkpOeSnGZJA0lJz+PbxPL51VYahaau9jT30NOiLLC2VAPx0Nve3cpCjo0hcLRly0uHg2tg3wqIeR4cPCDoWegcAS4+d34NIYQQog5lbUym+FJerZ7TprEDzk+0qLI9MTGRqKgodu7cibu7O5mZmSxevLisfdiwYUyYMAGAmTNnsmzZMiZPngxAUlISW7duRavVli3X3b17d0JDQxkyZAgjRowAwMnJifj4eAIDA4mOji5bxrsy4eHhrF27luDgYPbs2YObmxsPB3UkoMjIhw0b0rljG7r17M2oEcMZNWLoXY5O3avz4FlRlMeADwAt8LGqqvPrug+3YjYXYaexpFMEuR/G0dge1xwNn08MorOPC1Y3zMRqPT0BSE1NpVmzZigaBefBzbFu6MC1L09i3+t9rKIXkR56hHSf6fxnxU58mk6mQ08f/ti0AS95e/Bzdh7rLl8j9uo11l2+RlOdDRO9PXjG0w3dPSo4rrOuJr8638jp9F9nqk+n5XE6LY//nkyj+IZ613pbq1+D6XKz1g4YbrfMnoM7PDIFur9iSenYtwx2/h1+fB9a9oeHnoNWIZZqH0IIIYQos23bNkaMGIG7uzsArq7lFzFLSEhg5syZZGVlkZubW24FwJEjR6LV3vo33+PHj2fFihW89957xMTEsG/fviqPDQsLo3v37rz77rusXbuW8PBwAOxsrdnx/Xds/3E3G7/+ltde/TO7f/qZBX+bU7fFDu5SnUYiiqJogf8DBgAXgJ8VRYlTVfVoXfajOkajkfySLBw1tgB0a7CfjLQumIpb0Lmpc7nAGcDBwQFHR0dSU1PL7+/cECt3OzLWHMXZ/1X08d9y6eKn0H0jVzJ/JmHBBFoF9iSof1O6Ouvp6qzn7VZN2JyWxZpLGcw8eZEPz17lZZ8GPNPYDZs6XGjFyd6aoKYuBDV1KbffZFa5lFVASuksdUq6JR3k4PmKaSC/lNlr7qFHzTZibnSF5u56vFzsKoxhORrNr6kdWefhwGrLjPTa0aBvBJ2etcxIy2y0EEKI+1B1M8T3iqqq1f4mOCIigtjYWAICAli5ciXbt28va3NwqFjAoDLDhw9n9uzZ9O3bl6CgINzcql5F2dvbG19fX3bs2EFMTAy7d+8ua1MUhT49u9PrkW4MChnASy9M5PlXpuGht6WBwbZGfalvdT2N1xU4parqaQBFUdYCTwL3TfBsMplIyz6KydELgLxDfti6XiZfbcHqt2dh72BGVTSk2ThiRgMaM/lFuRw5cpikczf/FKais7Wlc2F79PZdyL/mjtWGTTDgLI17ziH1fGtOLGmKsdAOFVCxRJ+DgXaOjfjBK4i/Fht59/AxQs4dpEFBVo3vo0QxYUa99YGWboJacRGYW9EArYBWVoBH6aluvGQukGv5x/y/r3bwvwoX/VW12R/KcDCoaADlYD4c/AgVsPT4QazSofLf/d/Vdyd+J2Qsa5eMZ+2S8axd9248BzwyhEuXL976wHvEL6Ajz48bT9joMFxdXbh27Ro5udcxqyYuXb5IdnY2ihbOnj/D8hXLadSoEZcuXyS/IJ/MrIyyvl/LvkZefi6XLl9Eo1U4f+Fcuft6pGcPXnjhBRa9u/CW9zvo8UFMmjwJb28vNFYKly5f5PLly6RdTcPP3w+AQ/t24ePtiZs2B3NBDpcLoLi4iKzM9Hs3WLWgroPnJsD5G95fAILruA/V0trYcq1JI840PI71NRMZ19JxdEwHelBwtQ8FvxxXugEc63CZVkVJFGVX/ImpCNhmdcwy0rYA3dAe6kzTpkdo7HUMp6ZJlfajJdAfOKR24jPds3zaplft3qgQQgghasXDNgpp9i63PvAecQ16mOdem85TI55Gq9XSxj+Axk19UK3tSLN3IXLmWwx6/Ek8mzalVfsO5OXmkGbvQqGVDddt9GV9z7Gxp8BKR5q9C4+OeoY5L0/io+WrWLQ6Gu/mzekzeiybvt5C+8FPkXaLVI9uT4/hrTfeYto775ad/4pVDm/NnUra5cvY6GxxcXNn5vuLSbN3ZdvGOOb/5c9cS08nfMyzdOrUiS1bttzzsbsTiqrWcHayNi6mKCOBEFVVx5e+fxboqqrq5BuOmQhMBGjYsGHntWvX1ln/AMwqzEvewQSn79GZMzn5pS+2BitcvVujmq34ya0tB9za0jUtAdeCPJzPduB6o1MUOJ+v4oy/zoym57pjzG+Ag7YIN9scnAquYWd7HWtdHigqiqrFyuyKRrXChuvoyaQEM0WKDUcdvSmuJt9XBYoVE0bFiAYFa7MVmlvNyppKUM0lgAalBvlOQgghhKhoSOcBNPX9/acT/vuf/ybn+nVem/6Xe3odbYkZB4PTPb3GqVOnyM7OLrevT58++1VVvWWB6bqeeb4AeN/w3gu4dOMBqqouAZYAPPTQQ2rv3r3rrHO/WJcUi5vbRYovP4Rnp44UXLnE6Lfe4XhuAX/5+TgOhfs4nraVQefGo5hLaJ2QSWjzD7Fu3tFSYq3dE+XqFauqyrvfJrH6h1M0beZMUkt7mjvoeL+tN8HOlhItF5Ou8c1HCRjNJh5rsgKvvDh4bD4EW+odDqumvwnpCfx5+5+5kn+Fka1HEhkYiavOtcrjczMz2Pzhu5xPPEzbHr3oP/6P2NrXrN70ndi+fTv18ff4eyXjWXtkLGuXjGftkvGsXfdyPI8dO0aTBo3vybnvF0OHDiU5OZlt27Zha2uLwVCx4MBviU6nIygo6I4+W9fB889AK0VRmgEXgTBgdB33oXrGQlpqrgJQoASxpbCYNpmZHMtIYmj8KcyqgZ4pe3no+HPoCy6gFBsx+bbF+vX4Sh9iU1WVOZuOsXxnCnY+ek62smeidwOmN/fEvvTBuYT/XuR/a5NwdNHwuOEtnItOQthn0Oaxaruqqiqfn/icd35+Bw87Dz4Z/Akd3TtW+5nzR4+w6e8LKC4sIOTFV+jQu//dlZsTQgghxO/ehg0byl7n5OQAloA6JSWl3HELFiwoV83j96hOg2dVVUsURZkEbMGSMrxcVdXEuuzDrRQVFdLQLpMik5b9Bj+KrA+jGI0M3rmJAkNfRidF0+bIcOzVLAL2/x+XR0dxLt0O1blphSQJk1nlLzGHidl/gRIfBxwD3VnezodupbPNJcUm/vd5Ekd3ptK0mcpA4wRsra1h7Dfg6V9tP/ON+czePZvNKZvp2aQn83rOw8m26l9xqKrKwa/j2L5mGc4NPXn6zb/h5tX0bodLCCGEEA+oGwPqB0mdF81VVXUzsLmur1tTJTbWaNzPkmLUE61Y8ZDGiHVJMYUOj9I5K4k2CSHY26n4f/cuDZ8ZidqlPSe/OElhrhE7w68r4hlNZp75ZB97j6VR0tzAc72b83qLxmWzzRkXc9m68ijp53Pp7H+NrlcnomnUDkavsyweUo3TWaeZun0qKddTmBw0mfF+49EoVZd/MxYV8u1H/+D4zh20eOhhBv1xCrb2NStNI4QQQgghfiUrTtxEQzFu1sX8nNeIQkNDvIsvoQBas0qCfUs0XUoY/P0qbLv40+DPUylOtvzqIu18Dk3bW2oensjJZ/Sqn8m4kItTe1eWhvrRtXS2ubiwhP3fnCX+23PY2FvxeLd4fFNmQ+tBMPxjsNVX27+vU77mrV1vYWdlx5IBSwj2rL5YSdaVy8S9G0XauTP0GPUswU+NRKnDmtFCCCGEEL8nEjzfxM7GhbkX3XDO1NLL/zpNvTtjTrxAl9O5FOj1JDYw83PEBOYr0OvYeYJ1dqDAlZTruLV2ZtGpSyzfeAIlo4i+PZvyr0EdsFEUrqcXkHwgjfjvz5GfXUzbrh70sF2M7uQ66DrR8nCgpuqKF8WmYhb+vJC1J9YS1CCIhY8upKFDw2rvJSV+P5sXL0RFZdi0t2gWdMsHSIUQQgghRDUkeL6JqqrkmAtpmmHNm82b8urxk/QBnjhdRPeM/1Dy8w4uL1vBdid3tqRf59uM67xk0PLdkcuMc8ghf9cVPK8ZGefflPZ5Or5ZfIj0C7kU5hoB8GzpxKCxPjTa/Tyc3AsDo6DbH6tdJeRS7iVe3fEqR9KP8If2f+BPnf+Etabq5a9VVeWn2C/48fM1eHj7EPrnGTg38qztoRJCCCGEeOBI8HwTk8rJMXwAACAASURBVNlEaG4vTKkneD3xGvkayxA97JKA+p8tNJk1i44PBdIfmNsKTuQV8sXhIzgdy2H0hXwMJRoUdBh3ppForcG1iZ5mAe64exnw6eiKk+46rBwCWedg5EroMLTa/uy8uJNp/5tGibmE93q/xwCfAdUebyws5Jt//Z2kPT/StkcvBk6cjLVOV0ujI4QQQojfglmzZqHX63n11Vdr/Jm4uDiOHj3K9OnTiY2NpXXr1rRv3/62r1tUVMS8efPK9sXHxxMeHs6xY8dYvnw577//PoqiYDabiYqK4sknn+S1115j48aN2NjY0KJFC1asWIGzs/NtXbuuSPB8E61Gi/vPnlzUF7LbXuFZkyXwvL4uGu/QJ3Ae9XS549s46Hi8mxdfnT5GGmZadvWks19DXJs44ORuh6K5YUY5Lx1WPgnXL8GzG8C3R5X9UFWVpUeW8uHBD2nh3IL3e7+Pr5NvtX2/nn6V/yyM4urZ0zz6zDgeGjJUytAJIYQQ4pZKSkoIDQ0lNDQUgNjYWIYMGXLbwXN4eDiDBg0qFzyvXbuW0aNHc+HCBaKiojhw4ABOTk7k5uaSlpYGwIABA5g3bx5WVlZMmzaNefPmsWDBgtq7wVokwfNNFEXBoWERP7fpjV5ReK57S77+L6j2djR6880KwejptFwmbTvGdWcjy5/rQhffKhYnKcyGNUPh2hkY80W1gXOxqZhZu2ax8fRGBjcbzFvd3sLeuvpFTC4eP0rce3+jpLiYodPepHlQl9u9dSGEEEL8Rq1evZpFixahKAr+/v60aNGirG3p0qUsWbKE4uJiWrZsyZo1a7C3tyciIgJXV1cOHjxIp06d8PPzY9++fYwePZq4uDh27NjB3LlziYmJYeTIkRw4cACwrM43fvx49u/fX6Efbdq0wdnZmb179xIcbClqsG7dOrZs2cLVq1cxGAzo9ZbiCHq9vuz1wIEDy87x8MMPs379+ns2VndLgudKFOvNnPBtx0Qvd/QZ5wDQPfIIWn35ShiHzmfx3MqfUYDPJj5MxyZV1FkuzoPop+HqMQj/DJo9WuW1swqz+NP2P7H/yn4mBU5iov/EW84eJ2zfyndLPsTRw4On35qHWxPvao8XQgghxL3x9ddfc/ny5Vo9Z6NGjRg0aFCV7YmJiURFRbFz507c3d3JzMxk8eLFZe3Dhg1jwoQJAMycOZNly5YxefJkAJKSkti6dStarZaVK1cC0L17d0JDQxkyZAgjRowAwMnJifj4eAIDA4mOjiYiIqLK/oSHh7N27VqCg4PZs2cPbm5utGrVCpPJRMOGDWnWrBn9+vVj2LBhPPHEExU+v3z5ckaNGnW7w1RnpGZZJc7a6TFrNPR3cyT/+20A6B4pP1P836Q0wpfuwcFWy/rI7lUHziXF8PmzcOEnGL4UWlWds3zu+jme+foZDqcdZkHPBbwQ8EK1gbPZbGLHJ8vZ8q+/49WuA6Oj3pPAWQghhHjAbNu2jREjRuDu7g6Aq2v534InJCTQs2dP/Pz8iI6OJjHx1/XpRo4ciVZbdbWvX4wfP54VK1ZgMpmIiYlh9OiqF4gOCwtj/fr1mM1m1q5dS3h4OABarZZvvvmG9evX07p1a6ZMmcKsWbPKfTYqKgorKyvGjBlT09uvczLzXInzDi4AtCspJiUmBlo2Bpdfk9a3JF7mj9EHaNXQwKrnutDAsYoH8swm+HICJH8Pof+o9uHAg1cP8vK2lwFYFrKMoAbVr7delJ/P5n8s5PSBnwkMeZzef5iA1kr+OoUQQoj6VN0M8b2iqmq1k20RERHExsYSEBDAypUr2b59e1mbg0PNFk0bPnw4s2fPpm/fvgQFBeHm5lblsd7e3vj6+rJjxw5iYmLYvXt3WZuiKHTt2pWuXbsyYMAAnnvuubIAetWqVWzatInvv//+vn5mS2aeK3HR4EqDwlzszpxGU1wMQElREQBHL11n8mcH8fNy4vMXHq46cFZV2PgKHI2FgXOh0x+qvN7m05t5fsvzONk6ET04+paBc9aVy3z2xqukxO+n3/Mv0W9cpATOQgghxAOqX79+rFu3joyMDAAyMzPLtefk5ODp6YnRaCQ6OrpG5zQYDOTk5JS91+l0hISEEBkZWaNZ4fDwcKZMmUKLFi3w8vIC4NKlS2V502CpwuHj4wPAN998w4IFC4iLi8PevvrnvOqbBM+VuOTSgOZFeRSfPYvWrAKWJa5zi0qY9OkBXOyt+fgPD+Goq6LWsqrClr/CwTXw6F+g++QqDlNZcngJ0/43DX8Pfz4Z9AlNHZtW27cLRxOInjGVvGuZjJgxh8CBg+/qXoUQQgjx29ahQwdmzJhBr169CAgIYOrUqeXa58yZQ3BwMAMGDKBt27Y1OmdYWBgLFy4kKCiI5ORkAMaMGYOiKPTr1++Wnx85ciSJiYmEhYWV7TMajbz66qu0bduWwMBAPv/8cz744AMAJk2aRE5ODgMGDCAwMJAXX3yxprdf52S68iZ5JhP2+bm0tSqh+Ow5tFrLEBmLCnkjNoEzGXl8OuFh3PS2VZ9k+3zY808IjoQ+f630EKPJyKzds4hLjmNI8yHM7j4bG61NtX07/P0Wvl/2T5waejL0L2/g4tnkju9TCCGEEL8fY8eOZezYsZW2RUZGEhkZWWH/Lw8I/iIiIqLsQcAePXpw9OjRcu0//vgj48aNq1GOtIeHB0ajsdw+Hx8ftm3bVunxp06duuU57xcSPN/EToFJP22m2+NPUrz9LLrGjUFROJySxoYrDkzp35qHm1ed58OuD2HHfAh6BkL+VunKgdcKrzFl+xT2X9nPSwEv8WLAi9U/GGgysWPNMg58HYePfxBD/jQNnYO+yuOFEEIIIWrT0KFDSU5OrjL4fZBI8HwTjUZLqyEj6Ni7N6f//n/Y+vigzU/jxxOpdO/cmUl9W1b94f0r4dsZ0P4peGIxaCpmxVzKvcSEbydwOe8yC3ouYHDz6tMu8rKu8dUH73D+6BGCBj1B72fHo6nBT3xCCCGEELVlw4YNZa9/yYUeOnQoKSkp5Y5bsGABISEhddq3uibBcxVUVaX43DmU4G7kJ2Zgp5hZGBaIVlPFDPGR9bDxT9BqIAxbCpqKAe75nPM8v+V5co25LAtZRmCDwGr7cCnpGBvfm0dhbi6PvTSFDr1unWMkhBBCCFEXbgyoHyQSPFfBlJmJWlDAIqUV7sTT3cdAA0MVlTVOfAMbXgCfHvD0arCqmLt89vpZxm0ZR7GpmI8Hfkx7t+qXuzz50y42L16Eg6sr4XMX0cC3eW3clhBCCCGEuAtSbaMKxgsX+G/jAL7KtsVRb4+LbRUzzin/hXV/gEZ+ltUDre0qHHIm+wzjvhmH0WRkWciyWwbOh77bzMb35uPh04zRc9+VwFkIIYQQ4j4hM89VSEs+z4eBw/D30NEAAyXFRRUPOv8TfBoGrs3hmS9B51jhkJTsFJ7f8jwm1cSykGW0cmlV7XUPffc1Wz/+J807dWHIK9Ow1lUx2y2EEEIIIeqczDxX4eOj2eRa2zF/ZCDWtrYYCwvLH3DxAHwyHAwN4Q+xYO9a4Rwp2SmM2zLOEjgPvHXgnLTnR7YuswTOoX+eIYGzEEIIIcR9RoLnShSWqHyRY6B35gnaN3WzBM83zjxfOQprhoKdM4zdCIZGFc5xOus047aMQ1VVlocsp6VLNVU6gLOH49n8j0U0bt2OIX+aJisGCiGEEOKOzZo1i0WLFt3WZ+Li4pg/fz4AsbGxFeo81/S6r7/+erl98fHxtGvXjoiICD766KNybbGxsQwebKk8FhUVRYcOHfD39ycwMJC9e/cC8OGHH9KyZUsURSE9Pf22+1TbJHiuxKksMwWKlsHmywBY2dww81xwDT59Gqx0MHYTOHlV/Py1Uzy35TkAlocsp4Vzi2qvl3ryBP9ZNBeXxl4M/cubWNvKjLMQQggh6k5JSQmhoaFMnz4duPPgOTw8nM8//7zcvrVr1zJ69GjCw8NZu3Zthbbw8HB2797Npk2bOHDgAIcPH2br1q14e3sDlgVbtm7dWraUd32T4LkSp7JMKKqKn70ZADuDgYKc65ZltzdNhZxUCPsUXCr+JSZdS2LclnFoFS3LQ5bT3Ln6h/3Szp3hy3lv4eDswvC/vo1OL4ufCCGEEOL2rF69Gn9/fwICAnj22WfLtS1dupQuXboQEBDA8OHDyc/PBywrCk6dOpU+ffowbdo0Vq5cyaRJk9i1axdxcXG89tprBAYGkpycTKdOncrOd+rUKTp37lxpP9q0aYOzs3PZrDHAunXrCAsLo3///hw/fpzU1FQA8vPz2bp1K0899RSpqam4u7tja2tZwdnd3Z3GjRsDEBQUhK+vb62N1d2S3IBKnLpmplneVZzcLA8AOro3ID87i5IDn2KV+CX0nQleFb80JzJPMP7b8dhobFj+2HJ8HKv/CSnjwjm+mDMDKxsbRsycg96lYt60EEIIIX47kpLmkJN7rFbPadC3o3XrN6psT0xMJCoqip07d+Lu7k5mZiaLFy8uax82bBgTJkwAYObMmSxbtozJkyeX9jeJrVu3otVqy5br7t69O6GhoQwZMoQRI0YA4OTkRHx8PIGBgURHR5ct412ZX2aYg4OD2bNnD25ubrRq1aqsL+vWreOVV14hLi6OPn36YDAYGDhwIG+//TatW7emf//+jBo1il69et3NsN0zMvN8E5NZJTnbRNv0FLSuLgA4ejQAIPafH/FTSQ9O2nYn89IFzCZT2eeOZRzj+W+fx1Zry4rHVtwycE4/f5Yv5sxAo9Ew8s2/4dSgYt60EEIIIcStbNu2jREjRuDu7g6Aq2v5ybiEhAR69uyJn58f0dHRJCYmlrWNHDkSbQ1WLh4/fjwrVqzAZDIRExPD6NGjqzw2LCyM9evXYzaby9IyfnFj6saNbXq9nv3797NkyRI8PDwYNWpUWTB/v5GZ55sYTWYeb2Km8/Z4rFxHAeDdrgM+ribSr9tx9qQG3psHgJW1DR7NmtPqmVBeOTAdvbWeZSHL8DZ4V3uNS0nH2DB/NlobG0bOnItr44p500IIIYT47aluhvheUVUVRaliPQos6RmxsbEEBASwcuVKtm/fXtbm4OBQo2sMHz6c2bNn07dvX4KCgnBzc6vyWG9vb3x9fdmxYwcxMTHs3r27rK1Hjx6kpqZy6NAhdu3aVS4HWqvV0rt3b3r37o2fnx+rVq2qdoa7vkjwfBOdtZYnnXJxTz+F1sUy82w4uooRDXfBS8soajGYzEvnybhwngvHEkjcvpWv1+/H0MbA8seW00TfpNrznz7wMxv/Ph+9iysjZsyRGWchhBBC3JV+/foxdOhQpkyZgpubG5mZmeXac3Jy8PT0xGg0Eh0dTZMm1ccqAAaDgZycnLL3Op2OkJAQIiMj+cc//nHLz4eHhzNlyhRatGiBl9evk4SKovD0008zduxYBg8ejK60LO+JEyfQaDRl6R3x8fH3zQOCN5O0jUpoci1fFis3V0g9DDsWgN9I8BuBrb09ni3b0LF3f5qOHEixtRm3HN0tA2dVVTm4ZROxC+fg1sSbsNnvSOAshBBCiLvWoUMHZsyYQa9evQgICGDq1Knl2ufMmUNwcDADBgygbdu2NTpnWFgYCxcuJCgoiOTkZADGjBmDoij069fvlp8fOXIkiYmJhIWFVWgLDw/n0KFD5dpyc3MZO3Ys7du3x9/fn6NHjzJr1iwAFi9ejJeXFxcuXMDf35/x48fX6B7uFZl5roTmuiV41jo7QexEsHeDQe+UOyYxI5GJ302kt7MTgUrLagPn7KuX+X75v0k5uI9mQQ8x5E/TsNFVXMZbCCGEEOJOjB07lrFjx1baFhkZSWRkZIX9N+cUR0RElKVJ9OjRo0Kpuh9//JFx48bVKEfaw8MDo9FYaVtQUBCqqpbb17lzZ3bt2lXp8S+//DIvv/zyLa9ZVyR4roTV5VRQFGwub4YrR2DUJ+VWEEzMSGTClgkYbAwE+/XjzM7dqGYziqb8RH5xQT57Y79g/1exKBoNfZ97gcCBj1c4TgghhBDifjZ06FCSk5PZtm1bfXel3knwXAnrU6ew69AMza73oPUgaDukrO1y3mVe2voSBhsDKx5bQfreI5zc9gPXLqfi2tgy+2w2m0j4YSs7P19DfnYW7Xr2oWf4WAxu7vV1S0IIIYQQd2zDhg1lr3/JhR46dCgpKSnljluwYAEhISF12re6JsHzTczFxdgkn8Z9ZEMoKYCBc6H0CdYiUxFTfphCkamIFY+toLG+Mbp2ll87nEs4hGvjJpxPPMwPq5aSdjaFxm3aM/Qvb9KoZev6vCUhhBBCiFp3Y0D9IJHg+SYKkPvcaBzy3ocOI8C9JWB54G/e3nkkZCTw9z5/p7mTZeVAF8/GOHo04NC3X3Hm0AGS9+3B4O7B4y+/Rpvuj1ZbOkYIIYQQQvy2SPB8E8XGBp2PFcqRQgh6pmz/+pPriTkZwwS/CfRr+utTpoqi0LRjIAk/fEt22lUeCfsDnR5/Emsb2/rovhBCCCGEuIckeK6Ey7UjoLUB764AHE47zN/2/o0eTXrwx8A/Vji+S+hw9C4uBIYMwcHZpa67K4QQQggh6ogEz5VwzjoCXl3A2o7c4lz+8t+/0NC+IQt6LkCrqViexbVxE3qMerYeeiqEEEIIIeqS1Ey7WVEu+twU8O0JQNTeKC7nXWZ+z/k42TrVc+eEEEIIIW5t1qxZLFq06LY+ExcXx/z58wGIjY2tUOe5ptd9/fXXy+2Lj4+nXbt2RERE8NFHH5Vri42NZfDgwQBERUXRoUMH/P39CQwMZO/evYBlcZY2bdrQsWNHxo0bV2X96LoiwfPNbPXs6r4Kuk5gy5ktbDq9iRf8XyCwQWB990wIIYQQ4p4oKSkhNDSU6dOnA3cePIeHh/P555+X27d27VpGjx5NeHg4a9eurdAWHh7O7t272bRpEwcOHODw4cNs3boVb29vwBI8Hz9+nCNHjlBQUMDHH398h3dZOyR4roTRxpFsK2vm7plLR7eOTPCfUN9dEkIIIYSo0urVq/H39ycgIIBnny2fSrp06VK6dOlCQEAAw4cPJz8/H7CsKDh16lT69OnDtGnTWLlyJZMmTWLXrl3ExcXx2muvERgYSHJyMp06dSo736lTp+jcuXOl/WjTpg3Ozs5ls8YA69atIywsjP79+3P8+HFSU1MByM/PZ+vWrTz11FOkpqbi7u6Ora2l4IK7uzuNGzcGYPDgwSiKgqIodO3alQsXLtTewN0ByXmuwpLDS8guymZZyDKsNDJMQgghhLi1N05eICG3oFbP2VFvx5xWXlW2JyYmEhUVxc6dO3F3dyczM5PFixeXtQ8bNowJEywTgTNnzmTZsmVMnjwZgKSkJLZu3YpWqy1brrt79+6EhoYyZMgQRowYAYCTkxPx8fEEBgYSHR1dtox3ZX6ZYQ4ODmbPnj24ubnRqlWrsr6sW7eOV155hbi4OPr06YPBYGDgwIG8/fbbtG7dmv79+zNq1Ch69epV7rxGo5E1a9bwwQcf3PYY1iaZea5EjimHT49/ylMtn6K1iyxwIoQQQoj717Zt2xgxYgTu7paVjF1dXcu1JyQk0LNnT/z8/IiOjiYxMbGsbeTIkWi1FYsh3Gz8+PGsWLECk8lETEwMo0ePrvLYsLAw1q9fj9lsLkvL+MWNqRs3tun1evbv38+SJUvw8PBg1KhRZcH8L1566SUeffRRevbsecv+3ksypVqJhIIESswlhLcNv/XBQgghhBClqpshvldUVa12UbaIiAhiY2MJCAhg5cqVbN++vazNwcGhRtcYPnw4s2fPpm/fvgQFBeHm5lblsd7e3vj6+rJjxw5iYmLYvXt3WVuPHj1ITU3l0KFD7Nq1q1wOtFarpXfv3vTu3Rs/Pz9WrVpVNsM9e/Zs0tLSKjxwWB9k5rkSh/MP09ihMW1d29Z3V4QQQgghqtWvXz/WrVtHRkYGAJmZmeXac3Jy8PT0xGg0Eh0dXaNzGgwGcnJyyt7rdDpCQkKIjIxkzJgxt/x8eHg4U6ZMoUWLFnh5/foDhaIoPP3004wdO5bBgwej0+kAOHHiBCdPniw7Lj4+Hh8fHwA+/vhjtmzZwmeffYZGU/+ha/334D6Tb8znROEJenv3lqW1hRBCCHHf69ChAzNmzKBXr14EBAQwderUcu1z5swhODiYAQMG0LZtzSYGw8LCWLhwIUFBQSQnJwOWqheKotCvX79bfNqSDpKYmEhYWFiFtvDwcA4dOlSuLTc3l7Fjx9K+fXv8/f05evQos2bNAuDFF1/kypUrdOvWjcDAQN5+++0a3cO9ImkbN7HR2jDRYyID2w6s764IIYQQQtTI2LFjGTt2bKVtkZGRREZGVth/c05xREREWZpEjx49KpSq+/HHHxk3blyNcqQ9PDyqrMccFBSEqqrl9nXu3Jldu3ZVenxJScktr1eXJHi+iZXGirZ2bWnu1Ly+uyKEEEIIcV8YOnQoycnJbNu2rb67Uu8keBZCCCGEENXasGFD2etfcqGHDh1KSkpKueMWLFhASEhInfatrknwLIQQQgghbtuNAfWDRB4YFEIIIYS4Szfn8Ir7193+XUnwLIQQQghxF3Q6HRkZGRJA/waoqkpGRkZZibw7IWkbQgghhBB3wcvLiwsXLpCWllbfXakThYWFdxV81jedTleu9vTtkuBZCCGEEOIuWFtb06xZs/ruRp3Zvn07QUFB9d2NeiNpG0IIIYQQQtSQBM9CCCGEEELUkATPQgghhBBC1JAEz0IIIYQQQtSQBM9CCCGEEELUkATPQgghhBBC1JAEz0IIIYQQQtSQBM9CCCGEEELUkATPQgghhBBC1JAEz0IIIYQQQtSQBM9CCCGEEELUkATPQgghhBBC1JAEz0IIIYQQQtSQBM9CCCGEEELUkKKqan33oUqKoqQBZ+vh0u5Aej1c9/dKxrN2yXjWHhnL2iXjWbtkPGuXjGft+b2OpY+qqh63Oui+Dp7ri6Io+1RVfai++/F7IeNZu2Q8a4+MZe2S8axdMp61S8az9jzoYylpG0IIIYQQQtSQBM9CCCGEEELUkATPlVtS3x34nZHxrF0ynrVHxrJ2yXjWLhnP2iXjWXse6LGUnGchhBBCCCFqSGaehRBCCCGEqCEJnm+iKMpjiqKcUBTllKIo0+u7P78FiqKcURTliKIo8Yqi7Cvd56ooyneKopws/dOldL+iKMri0vE9rChKp/rtff1TFGW5oihXFUVJuGHfbY+foihjS48/qSjK2Pq4l/tBFeM5S1GUi6Xf0XhFUQbf0PZ66XieUBQl5Ib9D/z/BYqieCuK8oOiKMcURUlUFOWV0v3y/bwD1YynfD/vgKIoOkVRflIU5VDpeM4u3d9MUZS9pd+1zxVFsSndb1v6/lRpu+8N56p0nB8k1YznSkVRUm74fgaW7n9w/72rqipb6QZogWSgOWADHALa13e/7vcNOAO437TvHWB66evpwILS14OBrwEFeBjYW9/9r+8NeBToBCTc6fgBrsDp0j9dSl+71Pe93UfjOQt4tZJj25f+O7cFmpX++9fK/wVl4+MJdCp9bQCSSsdMvp+1O57y/byz8VQAfelra2Bv6fduHRBWuv/fQGTp65eAf5e+DgM+r26c6/v+7qPxXAmMqOT4B/bfu8w8l9cVOKWq6mlVVYuBtcCT9dyn36ongVWlr1cBT92wf7VqsQdwVhTFsz46eL9QVfW/QOZNu293/EKA71RVzVRV9RrwHfDYve/9/aeK8azKk8BaVVWLVFVNAU5h+X9A/i/4//buJdSmKI7j+Pcf1yPkFRIGSFESohQZoJtrpgyMCGXCwExSZoYYyUAYIAOvmFEeY/K+8rpG5OaOvCby+Bus/772PZ2zz77nqnO1f5/anb3XXoNzfv3Pvuucvda5gLv3uvvD2P8KvABmofpsSUGejag+C0SdfYvDjtgcWAdcivba+szq9hKw3syMxjlXSkGejVT2/a7B80CzgHe54/cUX9gkceCmmT0ws93RNsPdeyH9wQCmR7syLmew+SnX5vbGrcXT2TQDlGdpcYt7GenbKNXnENXkCarPlpjZCDN7DPSRBmlvgU/u/jO65LPpzy3Ofwamojz71ebp7ll9Ho76PGZmo6OtsvWpwfNAVqdNP0fS3Gp3Xw50AXvMbG1BX2U8NI3yU67FTgDzgaVAL3Ak2pVnCWY2HrgM7HP3L0Vd67Qpzxp18lR9tsjdf7n7UmA26dviRfW6xaPybKI2TzNbDBwAFgIrSVMx9kf3yuapwfNA74E5uePZwIc2PZf/hrt/iMc+4CrpAvYxm44Rj33RXRmXM9j8lGsBd/8YfxR+Ayf5e0tWeTZhZh2kgd55d78SzarPFtXLU/U5dO7+CbhLmns7ycxGxql8Nv25xfmJpCleyrNGLs+NMd3I3f07cAbVpwbPNe4DC2Kl7ijSgoLrbX5Ow5qZjTOzCdk+0Al0k3LLVthuB67F/nVgW6zSXQV8zm7/ygCDze8G0Glmk+OWb2e0Cf0DvMxmUo1CynNrrMKfCywA7qFrAZBW0wOngBfufjR3SvXZgkZ5qj5bY2bTzGxS7I8FNpDmkd8BtkS32vrM6nYLcNvdncY5V0qDPF/mPigbaf54vj6r+X5v10rF4bqRVo++Js2bOtju5zPcN9Jq7yexPc8yI80juwW8iccp0W7A8cj3GbCi3a+h3RtwgXSr9gfpE/uuVvIDdpIWuvQAO9r9uoZZnmcjr6ekC/7MXP+DkecroCvXXvlrAbCGdLv1KfA4tk2qz3+ep+qztTyXAI8it27gULTPIw1+e4CLwOhoHxPHPXF+XrOcq7QV5Hk76rMbOMffX+So7Ptd/2FQRERERKQkTdsQERERESlJg2cRERERkZI0eBYRERERKUmDZxERERGRkjR4FhEREREpSYNnEREREZGSNHgWERERESlJg2cRaku4XgAAAAtJREFUERERkZL+ADHREYspDIvFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_lasso = linear_model.lasso_path(X_t, Y_t)\n",
    "pd.DataFrame(path_lasso[1].T, index=path_lasso[0], columns=X.columns).plot(figsize=[12, 9], grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225151.28373 1317950.28495\n"
     ]
    }
   ],
   "source": [
    "model_lasso = linear_model.Lasso(alpha=10)\n",
    "model_lasso.fit(X_t, Y_t)\n",
    "Yhat_t = model_lasso.predict(X_t)\n",
    "Yhat_v = model_lasso.predict(X_v)\n",
    "print(metrics.mean_squared_error(Y_t, Yhat_t), metrics.mean_squared_error(Y_v, Yhat_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3979.436,   -30.838,   -25.764,  -237.711,  -128.402,    -0.   ,\n",
       "          -0.   ,     9.816,   254.369,  -168.253,   267.921,   145.786,\n",
       "          -0.   ,    -0.   ,    94.485,    11.102,    31.61 ,    -0.   ,\n",
       "         -25.547,  -106.927,  -277.806,  -377.141,  -464.002,   584.63 ,\n",
       "         739.905,   294.953,   929.289,   963.859,   751.172,   856.191])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215760.98406 1315151.52614\n"
     ]
    }
   ],
   "source": [
    "model_ridge = linear_model.Ridge(alpha=400)\n",
    "model_ridge.fit(X_t, Y_t)\n",
    "Yhat_t = model_ridge.predict(X_t)\n",
    "Yhat_v = model_ridge.predict(X_v)\n",
    "print(metrics.mean_squared_error(Y_t, Yhat_t), metrics.mean_squared_error(Y_v, Yhat_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3925.144,   -21.855,   -21.84 ,  -284.757,  -133.916,  -133.955,\n",
       "          68.884,    11.211,   286.392,  -133.661,   439.727,   155.661,\n",
       "        -105.376,    80.591,   243.671,   148.562,   161.514,   -51.936,\n",
       "         -72.097,  -154.215,  -317.344,  -407.241,  -484.052,   581.679,\n",
       "         744.928,   314.009,   927.283,   960.895,   742.388,   848.527])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 / L2 beta of Lasso 11756.92 / 20619685.92\n",
      "L1 / L2 beta of Ridge: 12963.31 / 20550867.99\n",
      "L1 / L2 beta of linear reg: 21922.19 / 37426258.89\n"
     ]
    }
   ],
   "source": [
    "print(\"L1 / L2 beta of Lasso {:.2f} / {:.2f}\".format(np.abs(model_lasso.coef_).sum(), (model_lasso.coef_ ** 2).sum()))\n",
    "print(\"L1 / L2 beta of Ridge: {:.2f} / {:.2f}\".format(np.abs(model_ridge.coef_).sum(), (model_ridge.coef_ ** 2).sum()))\n",
    "print(\"L1 / L2 beta of linear reg: {:.2f} / {:.2f}\".format(np.abs(model_lm.coef_).sum(), (model_lm.coef_ ** 2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_train(X, Y, cvfold, f_model=linear_model.LinearRegression, f_loss=metrics.mean_squared_error, **kwargs):\n",
    "    model_L = []\n",
    "    for i_cv, ir_v in enumerate(cvfold):\n",
    "        ir_t = np.concatenate(np.delete(cvfold, i_cv))\n",
    "        print(\"CV fold: {} / {}, training / validation sample: {} / {}\".format(i_cv, len(cvfold), len(ir_t), len(ir_v)))\n",
    "        X_t, X_v = X.loc[ir_t], X.loc[ir_v]\n",
    "        Y_t, Y_v = Y.loc[ir_t], Y.loc[ir_v]\n",
    "        time_start = time.time()\n",
    "        model = f_model(**kwargs)\n",
    "        model.fit(X_t, Y_t)\n",
    "        Yhat_t = model.predict(X_t)\n",
    "        Yhat_v = model.predict(X_v)\n",
    "        loss_t = f_loss(Y_t, Yhat_t)\n",
    "        loss_v = f_loss(Y_v, Yhat_v)\n",
    "        print(\"    Model: {}, training / validation loss of {:.4f} / {:.4f}, time: {:.2f}s\".format(\n",
    "            model.__class__.__name__, loss_t, loss_v, time.time() - time_start))\n",
    "        model_L.append(model)\n",
    "    return(model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Lasso, training / validation loss of 1257281.4516 / 1178116.6709, time: 0.17s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Lasso, training / validation loss of 1232800.9340 / 1301651.6815, time: 0.17s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Lasso, training / validation loss of 1236627.0369 / 1672570.5187, time: 0.11s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: Lasso, training / validation loss of 1246959.6684 / 1202646.0025, time: 0.15s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: Lasso, training / validation loss of 1225151.2837 / 1317950.2849, time: 0.13s\n"
     ]
    }
   ],
   "source": [
    "model_L_lasso = cv_train(X, Y, cvfold, f_model=linear_model.Lasso, alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Ridge, training / validation loss of 1249698.5781 / 1167716.2816, time: 0.02s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Ridge, training / validation loss of 1224873.3657 / 1292738.6774, time: 0.02s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: Ridge, training / validation loss of 1225851.1420 / 2323788.9323, time: 0.02s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: Ridge, training / validation loss of 1240310.2826 / 1202394.9120, time: 0.02s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: Ridge, training / validation loss of 1215760.9841 / 1315151.5261, time: 0.01s\n"
     ]
    }
   ],
   "source": [
    "model_L_ridge = cv_train(X, Y, cvfold, f_model=linear_model.Ridge, alpha=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373436.6828441089"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso = linear_model.Lasso(alpha=10)\n",
    "model_lasso.fit(X.loc[ir_lab], Y.loc[ir_lab])\n",
    "Yhat_test = model_lasso.predict(X_test)\n",
    "metrics.mean_squared_error(Y_test, Yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1307695.1192697012"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge = linear_model.Ridge(alpha=400)\n",
    "model_ridge.fit(X.loc[ir_lab], Y.loc[ir_lab])\n",
    "Yhat_test = model_ridge.predict(X_test)\n",
    "metrics.mean_squared_error(Y_test, Yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn (3.3): Select Penalty Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to select best penalty coeffient $\\hat{\\lambda}$, or more generally, best hyperparameters of model?\n",
    "    - Step 1. Try different $\\lambda$ on the model\n",
    "        - Method 1: Build several models with different $\\lambda$\n",
    "        - Method 2: If exists, a stepwise model for $\\lambda$ can save computation time\n",
    "    - Step 2. Calculate CV validation loss, and select the $\\hat{\\lambda}$ minimizing it\n",
    "    - Step 3. If used for variable selection, choose important variables under $\\hat{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn(4.1): Decision Tree Models\n",
    "- Can we detect non-linear relationship without adding polynomial terms?\n",
    "- Non-linear models: e.g. tree-based methods $\\hat{Y} = Tree(X, \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0344067743 775654.118782\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree as tree\n",
    "model_tree = tree.DecisionTreeRegressor()\n",
    "model_tree.fit(X_t, Y_t)\n",
    "Yhat_t = model_tree.predict(X_t)\n",
    "Yhat_v = model_tree.predict(X_v)\n",
    "print(metrics.mean_squared_error(Y_t, Yhat_t), metrics.mean_squared_error(Y_v, Yhat_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat           0.644\n",
       "x y             0.220\n",
       "clarity_SI2     0.020\n",
       "carat y         0.014\n",
       "clarity_SI1     0.014\n",
       "y z             0.012\n",
       "color_J         0.012\n",
       "color_I         0.009\n",
       "color_H         0.007\n",
       "clarity_VVS1    0.005\n",
       "dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_tree.feature_importances_, X.columns).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 20.5502 / 724906.2633, time: 0.55s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 23.3130 / 835967.6493, time: 0.53s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 32.0173 / 737821.8172, time: 0.54s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 30.0136 / 860066.0633, time: 0.53s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 26.0344 / 784917.6993, time: 0.54s\n"
     ]
    }
   ],
   "source": [
    "model_L_tree = cv_train(X, Y, cvfold, tree.DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 160685.5519 / 663499.0495, time: 0.39s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 162957.4567 / 740674.4441, time: 0.39s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 163416.6810 / 694207.7732, time: 0.41s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 153775.0330 / 842325.5883, time: 0.40s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: DecisionTreeRegressor, training / validation loss of 166967.6538 / 709757.2085, time: 0.40s\n"
     ]
    }
   ],
   "source": [
    "# Limit the depth of tree to control model complexity\n",
    "model_L_tree = cv_train(X, Y, cvfold, tree.DecisionTreeRegressor, max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703881.66034046595"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = tree.DecisionTreeRegressor(max_depth=15)\n",
    "model_tree.fit(X.loc[ir_lab], Y.loc[ir_lab])\n",
    "Yhat_test = model_tree.predict(X_test)\n",
    "metrics.mean_squared_error(Y_test, Yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_predict(X, Y, model_L, f_loss=metrics.mean_squared_error):\n",
    "    Yhat_L = []\n",
    "    for i, model in enumerate(model_L):\n",
    "        Yhat = model.predict(X)\n",
    "        loss = f_loss(Y, Yhat)\n",
    "        print(\"CV fold: {} / {}, Model: {}, test loss: {:.4f}\".format(i, len(model_L), model.__class__.__name__, loss))\n",
    "        Yhat_L.append(Yhat)\n",
    "    print(\"Average CV predictor test loss: {:.4f}\".format(f_loss(Y, np.mean(Yhat_L, axis=0))))\n",
    "    return(np.vstack(Yhat_L).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, Model: DecisionTreeRegressor, test loss: 720827.3576\n",
      "CV fold: 1 / 5, Model: DecisionTreeRegressor, test loss: 821173.3539\n",
      "CV fold: 2 / 5, Model: DecisionTreeRegressor, test loss: 769580.6414\n",
      "CV fold: 3 / 5, Model: DecisionTreeRegressor, test loss: 828119.5141\n",
      "CV fold: 4 / 5, Model: DecisionTreeRegressor, test loss: 753521.4227\n",
      "Average CV predictor test loss: 529090.8605\n"
     ]
    }
   ],
   "source": [
    "Yhat_cv_tree = cv_predict(X_test, Y_test, model_L_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn(4.2): Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build $M$ trees at the same time in each model\n",
    "- To increase diversity of trees, when building each tree $\\hat{\\theta}_i$:\n",
    "    - Randomly bootstrap $(X, Y)$ to $(X_{(i)}, Y_{(i)})$ \n",
    "    - Randomly select a subset of variables $\\Theta_{i}$\n",
    "- $\\hat{\\theta}_i  = \\arg\\min_{\\theta_i \\in \\Theta_{i}}L\\left(Y_{(i)}, Tree(X_{(i)}, \\theta_i)\\right)$\n",
    "- $\\hat{Y} = \\frac{1}{M}\\sum_{i=1}^M Tree(X, \\hat{\\theta}_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: RandomForestRegressor, training / validation loss of 83297.8757 / 454464.0117, time: 3.50s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: RandomForestRegressor, training / validation loss of 83410.5577 / 493339.0047, time: 3.47s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: RandomForestRegressor, training / validation loss of 86083.9441 / 444552.3266, time: 3.48s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: RandomForestRegressor, training / validation loss of 85748.9303 / 494191.9059, time: 3.53s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: RandomForestRegressor, training / validation loss of 92420.4180 / 492346.8307, time: 3.46s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "model_L_rf = cv_train(X, Y, cvfold, ensemble.RandomForestRegressor, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cut_Very Good    2.163e-04\n",
       "cut_Good         2.278e-04\n",
       "cut_Premium      3.285e-04\n",
       "table            7.900e-04\n",
       "cut_Ideal        7.941e-04\n",
       "                   ...    \n",
       "clarity_SI2      1.887e-02\n",
       "y z              4.553e-02\n",
       "carat y          8.078e-02\n",
       "x y              1.198e-01\n",
       "carat            6.454e-01\n",
       "Length: 30, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([model.feature_importances_ for model in model_L_rf], columns=X.columns).mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-learn(4.3): Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build $M$ trees stepwisely for residuals in each model\n",
    "- To reduce over-fitting, when building each tree $\\hat{\\theta}_i$:\n",
    "    - Restrict max depth of tree\n",
    "    - Restrict step size $\\eta < 1$\n",
    "- $\\hat{\\theta}_i  = \\arg\\min_{\\theta_i \\in \\Theta}L\\left(Y - \\eta\\sum_{j=1}^{i-1}Tree(X, \\theta_j), Tree(X, \\theta_i)\\right)$\n",
    "- $\\hat{Y} = \\eta\\sum_{i=1}^M Tree(X, \\hat{\\theta}_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV fold: 0 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: GradientBoostingRegressor, training / validation loss of 217558.8845 / 404180.2179, time: 4.46s\n",
      "CV fold: 1 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: GradientBoostingRegressor, training / validation loss of 218540.9691 / 462562.2644, time: 4.81s\n",
      "CV fold: 2 / 5, training / validation sample: 31766 / 7942\n",
      "    Model: GradientBoostingRegressor, training / validation loss of 227652.8995 / 439257.5792, time: 4.52s\n",
      "CV fold: 3 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: GradientBoostingRegressor, training / validation loss of 213694.5172 / 449693.4169, time: 4.42s\n",
      "CV fold: 4 / 5, training / validation sample: 31767 / 7941\n",
      "    Model: GradientBoostingRegressor, training / validation loss of 215316.0274 / 442238.0211, time: 4.56s\n"
     ]
    }
   ],
   "source": [
    "model_L_gbt = cv_train(X, Y, cvfold, ensemble.GradientBoostingRegressor, n_estimators=100, learning_rate=0.2, max_depth=6, max_features=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cut_Good         0.002\n",
       "cut_Very Good    0.003\n",
       "cut_Premium      0.005\n",
       "cut_Ideal        0.007\n",
       "color_E          0.012\n",
       "                 ...  \n",
       "x z              0.058\n",
       "y z              0.060\n",
       "carat y          0.077\n",
       "carat x          0.078\n",
       "carat            0.168\n",
       "Length: 30, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([model.feature_importances_ for model in model_L_gbt], columns=X.columns).mean().sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
